{"title":"Building Models in R with tidymodels","markdown":{"yaml":{"title":"Building Models in R with tidymodels","date":"2024-10-12","categories":["R","Machine Learning","tidymodels"],"image":"../images/tidymodels.png","execute":{"echo":true,"warning":false,"message":false,"eval":true}},"headingText":"Required Packages","containsRefs":false,"markdown":"\n\nThe tidymodels framework provides a cohesive set of packages for modeling and machine learning in R, following tidyverse principles. In this post, we'll build a realistic credit scoring model using tidymodels.\n\nCredit scoring models are used by financial institutions to assess the creditworthiness of borrowers. These models predict the probability of default (failure to repay a loan) based on borrower characteristics and loan attributes. A good credit scoring model should effectively discriminate between high-risk and low-risk borrowers, be well-calibrated, and provide interpretable insights.\n\n\nFirst, let's load all the required packages for our analysis:\n\n```{r}\nlibrary(tidymodels)\nlibrary(xgboost)\nlibrary(vip)        # For variable importance\nlibrary(stringr)    # For string manipulation functions\nlibrary(probably)   # For calibration plots\nlibrary(ROSE)       # For imbalanced data visualization\nlibrary(corrplot)   # For correlation visualization\n```\n\n## Creating a Realistic Credit Scoring Dataset\n\nWe'll simulate a realistic credit dataset with common variables found in credit scoring models. The data will include demographic information, loan characteristics, and credit history variables.\n\n```{r}\nset.seed(123)\nn <- 10000  # Larger sample size for more realistic modeling\n\n# Create base features with realistic distributions\ndata <- tibble(\n  customer_id = paste0(\"CUS\", formatC(1:n, width = 6, format = \"d\", flag = \"0\")),\n  \n  # Demographics - with realistic age distribution for credit applicants\n  age = pmax(18, pmin(80, round(rnorm(n, 38, 13)))),\n  income = pmax(12000, round(rlnorm(n, log(52000), 0.8))),\n  employment_length = pmax(0, round(rexp(n, 1/6))),  # Exponential distribution for job tenure\n  home_ownership = sample(c(\"RENT\", \"MORTGAGE\", \"OWN\"), n, replace = TRUE, prob = c(0.45, 0.40, 0.15)),\n  \n  # Loan characteristics - with more realistic correlations\n  loan_amount = round(rlnorm(n, log(15000), 0.7) / 100) * 100,  # Log-normal for loan amounts\n  loan_term = sample(c(36, 60, 120), n, replace = TRUE, prob = c(0.6, 0.3, 0.1)),\n  \n  # Credit history - with more realistic distributions\n  credit_score = round(pmin(850, pmax(300, rnorm(n, 700, 90)))),\n  dti_ratio = pmax(0, pmin(65, rlnorm(n, log(20), 0.4))),  # Debt-to-income ratio\n  delinq_2yrs = rpois(n, 0.4),  # Number of delinquencies in past 2 years\n  inq_last_6mths = rpois(n, 0.7),  # Number of inquiries in last 6 months\n  open_acc = pmax(1, round(rnorm(n, 10, 4))),  # Number of open accounts\n  pub_rec = rbinom(n, 2, 0.06),  # Number of public records\n  revol_util = pmin(100, pmax(0, rnorm(n, 40, 20))),  # Revolving utilization\n  total_acc = pmax(open_acc, open_acc + round(rnorm(n, 8, 6)))  # Total accounts\n)\n\n# Add realistic correlations between variables\ndata <- data %>%\n  mutate(\n    # Interest rate depends on credit score and loan term\n    interest_rate = 25 - (credit_score - 300) * (15/550) + \n                    ifelse(loan_term == 36, -1, ifelse(loan_term == 60, 0, 1.5)) +\n                    rnorm(n, 0, 1.5),\n    \n    # Loan purpose with realistic probabilities\n    loan_purpose = sample(\n      c(\"debt_consolidation\", \"credit_card\", \"home_improvement\", \"major_purchase\", \"medical\", \"other\"), \n      n, replace = TRUE, \n      prob = c(0.45, 0.25, 0.10, 0.08, 0.07, 0.05)\n    ),\n    \n    # Add some derived features that have predictive power\n    payment_amount = (loan_amount * (interest_rate/100/12) * (1 + interest_rate/100/12)^loan_term) / \n                    ((1 + interest_rate/100/12)^loan_term - 1),\n    payment_to_income_ratio = (payment_amount * 12) / income\n  )\n\n# Create a more realistic default probability model with non-linear effects\nlogit_default <- with(data, {\n  -4.5 +  # Base intercept for ~10% default rate\n    -0.03 * (age - 18) +  # Age effect (stronger for younger borrowers)\n    -0.2 * log(income/10000) +  # Log-transformed income effect\n    -0.08 * employment_length +  # Employment length effect\n    ifelse(home_ownership == \"OWN\", -0.7, ifelse(home_ownership == \"MORTGAGE\", -0.3, 0)) +  # Home ownership\n    0.3 * log(loan_amount/1000) +  # Log-transformed loan amount\n    ifelse(loan_term == 36, 0, ifelse(loan_term == 60, 0.4, 0.8)) +  # Loan term\n    0.15 * interest_rate +  # Interest rate effect\n    ifelse(loan_purpose == \"debt_consolidation\", 0.5, \n           ifelse(loan_purpose == \"credit_card\", 0.4, \n                  ifelse(loan_purpose == \"medical\", 0.6, 0))) +  # Loan purpose\n    -0.01 * (credit_score - 300) +  # Credit score (stronger effect at lower scores)\n    0.06 * dti_ratio +  # DTI ratio effect\n    0.4 * delinq_2yrs +  # Delinquencies effect (stronger effect for first delinquency)\n    0.3 * inq_last_6mths +  # Inquiries effect\n    -0.1 * log(open_acc + 1) +  # Open accounts (log-transformed)\n    0.8 * pub_rec +  # Public records (strong effect)\n    0.02 * revol_util +  # Revolving utilization\n    1.2 * payment_to_income_ratio +  # Payment to income ratio (strong effect)\n    rnorm(n, 0, 0.8)  # Add some noise for realistic variation\n})\n\n# Generate default flag with realistic default rate\nprob_default <- plogis(logit_default)\ndata$default <- factor(rbinom(n, 1, prob_default), levels = c(0, 1), labels = c(\"no\", \"yes\"))\n\n# Check class distribution\ntable(data$default)\n```\n\n```{r}\nprop.table(table(data$default))\n```\n\n\n```{r}\n# Visualize the default rate\nggplot(data, aes(x = default, fill = default)) +\n  geom_bar(aes(y = ..prop.., group = 1)) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"Class Distribution in Credit Dataset\",\n       y = \"Percentage\") +\n  theme_minimal()\n```\n\n```{r}\n# Visualize the relationship between key variables and default rate\nggplot(data, aes(x = credit_score, y = as.numeric(default) - 1)) +\n  geom_smooth(method = \"loess\") +\n  labs(title = \"Default Rate by Credit Score\", \n       x = \"Credit Score\", y = \"Default Probability\") +\n  theme_minimal()\n```\n\n\n```{r}\n# Examine correlation between numeric predictors\ncredit_cors <- data %>%\n  select(age, income, employment_length, loan_amount, interest_rate, \n         credit_score, dti_ratio, delinq_2yrs, revol_util, payment_to_income_ratio) %>%\n  cor()\n\ncorrplot(credit_cors, method = \"circle\", type = \"upper\", \n         tl.col = \"black\", tl.srt = 45, tl.cex = 0.7)\n```\n\n\n## Data Splitting\n\nCredit default datasets are typically imbalanced, with defaults being the minority class. We'll use a stratified split to maintain the class distribution.\n\n```{r}\n# Create initial train/test split (80/20)\nset.seed(456)\ninitial_split <- initial_split(data, prop = 0.8, strata = default)\ntrain_data <- training(initial_split)\ntest_data <- testing(initial_split)\n\n# Create validation set from training data (75% train, 25% validation)\nset.seed(789)\nvalidation_split <- initial_split(train_data, prop = 0.75, strata = default)\n\n# Check class imbalance in training data\ntrain_class_counts <- table(training(validation_split)$default)\ntrain_class_props <- prop.table(train_class_counts)\n\ncat(\"Training data class distribution:\\n\")\nprint(train_class_counts)\ncat(\"\\nPercentage:\\n\")\nprint(train_class_props * 100)\n\n# Visualize class imbalance\nROSE::roc.curve(training(validation_split)$default == \"yes\", \n                training(validation_split)$credit_score,\n                plotit = TRUE,\n                main = \"ROC Curve for Credit Score Alone\")\n```\n\n## Feature Engineering and Preprocessing\n\nNow we'll create a comprehensive recipe with feature engineering steps relevant to credit scoring, including handling the class imbalance.\n\n```{r}\n# Examine the distributions of key variables\npar(mfrow = c(2, 2))\nhist(training(validation_split)$credit_score, \n     main = \"Credit Score Distribution\", xlab = \"Credit Score\")\n\nhist(training(validation_split)$dti_ratio, \n     main = \"DTI Ratio Distribution\", xlab = \"DTI Ratio\")\n\nhist(training(validation_split)$payment_to_income_ratio, \n     main = \"Payment to Income Ratio\", \n     xlab = \"Payment to Income Ratio\")\n\nhist(log(training(validation_split)$income), \n     main = \"Log Income Distribution\", xlab = \"Log Income\")\n\npar(mfrow = c(1, 1))\n```\n\n```{r}\n# Create a comprehensive recipe with domain knowledge\ncredit_recipe <- recipe(default ~ ., data = training(validation_split)) %>%\n  # Remove ID column\n  step_rm(customer_id) %>%\n  \n  # Convert categorical variables to factors\n  step_string2factor(home_ownership, loan_purpose) %>%\n  \n  # Create additional domain-specific features\n  step_mutate(\n    # We already have payment_to_income_ratio from data generation\n    # Add more credit risk indicators\n    credit_utilization = revol_util / 100,\n    acc_to_age_ratio = total_acc / age,\n    delinq_per_acc = ifelse(total_acc > 0, delinq_2yrs / total_acc, 0),\n    inq_rate = inq_last_6mths / (open_acc + 0.1),  # Inquiry rate relative to open accounts\n    term_factor = loan_term / 12,  # Term in years\n    log_income = log(income),  # Log transform income\n    log_loan = log(loan_amount),  # Log transform loan amount\n    payment_ratio = payment_amount / (income / 12),  # Monthly payment to monthly income\n    util_to_income = (revol_util / 100) * (dti_ratio / 100)  # Interaction term\n  ) %>%\n  \n  # Handle categorical variables\n  step_dummy(all_nominal_predictors()) %>%\n  \n  # Impute missing values (if any)\n  step_impute_median(all_numeric_predictors()) %>%\n  \n  # Transform highly skewed variables\n  step_YeoJohnson(income, loan_amount, payment_amount) %>%\n  \n  # Remove highly correlated predictors\n  step_corr(all_numeric_predictors(), threshold = 0.85) %>%\n  \n  # Normalize numeric predictors\n  step_normalize(all_numeric_predictors()) %>%\n  \n  # Remove zero-variance predictors\n  step_zv(all_predictors())\n\n# Prep the recipe to examine the steps\nprepped_recipe <- prep(credit_recipe)\nprepped_recipe\n\n# Check the transformed data\nrecipe_data <- bake(prepped_recipe, new_data = NULL)\nglimpse(recipe_data)\n\n# Verify class balance after SMOTE\ntable(recipe_data$default)\n```\n\nThe feature engineering steps above incorporate domain knowledge specific to credit risk modeling:\n\n- We create derived features that capture payment capacity, credit utilization, and borrower stability\n- We transform highly skewed variables using Yeo-Johnson transformations\n- We normalize all numeric predictors to put them on the same scale\n\n## Model Specification and Tuning\n\nFor credit scoring, we'll compare two models: a logistic regression model (commonly used in the financial industry for its interpretability) and an XGBoost model (for its predictive power). We'll tune both models using cross-validation.\n\n```{r}\n# Define the logistic regression model\nlog_reg_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\n# Create a logistic regression workflow\nlog_reg_workflow <- workflow() %>%\n  add_recipe(credit_recipe) %>%\n  add_model(log_reg_spec)\n\n# Define the tuning grid for logistic regression\nlog_reg_grid <- grid_regular(\n  penalty(range = c(-5, 0), trans = log10_trans()),\n  mixture(range = c(0, 1)),\n  levels = c(10, 5)\n)\n\n# Define the XGBoost model with tunable parameters\nxgb_spec <- boost_tree(\n  trees = tune(),\n  tree_depth = tune(),\n  min_n = tune(),\n  loss_reduction = tune(),\n  mtry = tune(),\n  learn_rate = tune()\n) %>%\n  set_engine(\"xgboost\", objective = \"binary:logistic\", scale_pos_weight = 5) %>%\n  set_mode(\"classification\")\n\n# Create an XGBoost workflow\nxgb_workflow <- workflow() %>%\n  add_recipe(credit_recipe) %>%\n  add_model(xgb_spec)\n\n# Define the tuning grid for XGBoost\nxgb_grid <- grid_latin_hypercube(\n  trees(range = c(100, 500)),\n  tree_depth(range = c(3, 10)),\n  min_n(range = c(2, 20)),\n  loss_reduction(range = c(0.001, 1.0)),\n  mtry(range = c(5, 20)),\n  learn_rate(range = c(-4, -1), trans = log10_trans()),\n  size = 15\n)\n\n# Create cross-validation folds with stratification\nset.seed(234)\ncv_folds <- vfold_cv(training(validation_split), v = 3, strata = default)\n\n# Define the metrics to evaluate\nclassification_metrics <- metric_set(\n  roc_auc,  # Area under the ROC curve\n  pr_auc,    # Area under the precision-recall curve\n)\n\n# Tune the logistic regression model\nset.seed(345)\nlog_reg_tuned <- tune_grid(\n  log_reg_workflow,\n  resamples = cv_folds,\n  grid = log_reg_grid,\n  metrics = classification_metrics,\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n# Tune the XGBoost model\nset.seed(456)\nxgb_tuned <- tune_grid(\n  xgb_workflow,\n  resamples = cv_folds,\n  grid = xgb_grid,\n  metrics = classification_metrics,\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n# Collect and visualize logistic regression tuning results\nlog_reg_results <- log_reg_tuned %>% collect_metrics()\nlog_reg_results %>% filter(.metric == \"roc_auc\") %>% arrange(desc(mean)) %>% head()\n```\n\nThe results above show how both models perform across different hyperparameter settings. XGBoost typically achieves higher predictive performance, while logistic regression offers better interpretability. For credit scoring applications, both aspects are important.\n\n## Finalizing and Evaluating the Models\n\nWe'll finalize both models using their best hyperparameters and evaluate them on the validation set.\n\n```{r}\n#| label: model-evaluation\n\n# Select best hyperparameters based on ROC AUC\nbest_log_reg_params <- select_best(log_reg_tuned, metric = \"roc_auc\")\nbest_xgb_params <- select_best(xgb_tuned, metric = \"roc_auc\")\n\n# Finalize workflows with best parameters\nfinal_log_reg_workflow <- log_reg_workflow %>%\n  finalize_workflow(best_log_reg_params)\n\nfinal_xgb_workflow <- xgb_workflow %>%\n  finalize_workflow(best_xgb_params)\n\n# Fit the final models on the full training data\nfinal_log_reg_model <- final_log_reg_workflow %>%\n  fit(data = training(validation_split))\n\nfinal_xgb_model <- final_xgb_workflow %>%\n  fit(data = training(validation_split))\n\n# Make predictions on the validation set with both models\nlog_reg_val_results <- final_log_reg_model %>%\n  predict(testing(validation_split)) %>%\n  bind_cols(predict(final_log_reg_model, testing(validation_split), type = \"prob\")) %>%\n  bind_cols(testing(validation_split) %>% select(default, customer_id))\n\nxgb_val_results <- final_xgb_model %>%\n  predict(testing(validation_split)) %>%\n  bind_cols(predict(final_xgb_model, testing(validation_split), type = \"prob\")) %>%\n  bind_cols(testing(validation_split) %>% select(default, customer_id))\n\n# Evaluate model performance on validation set\nlog_reg_val_metrics <- log_reg_val_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\nxgb_val_metrics <- xgb_val_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\ncat(\"Logistic Regression Validation Metrics:\\n\")\nprint(log_reg_val_metrics)\n\ncat(\"\\nXGBoost Validation Metrics:\\n\")\nprint(xgb_val_metrics)\n```\n\n## Feature Importance and Model Interpretation\n\nUnderstanding which features drive the predictions is crucial for credit scoring models.\n\n```{r}\n#| label: feature-importance\n#| fig-width: 10\n#| fig-height: 12\n\n# Extract feature importance from XGBoost model\nxgb_importance <- final_xgb_model %>%\n  extract_fit_parsnip() %>%\n  vip(num_features = 15) +\n  labs(title = \"XGBoost Feature Importance\")\n\nxgb_importance\n\n# Extract coefficients from logistic regression model\nlog_reg_importance <- final_log_reg_model %>%\n  extract_fit_parsnip() %>%\n  vip(num_features = 15) +\n  labs(title = \"Logistic Regression Coefficient Importance\")\n\nlog_reg_importance\n\n# Create calibration plots for both models\nlog_reg_cal <- log_reg_val_results %>%\n  cal_plot_breaks(truth = default, estimate = .pred_yes) +\n  labs(title = \"Logistic Regression Probability Calibration\")\n\nxgb_cal <- xgb_val_results %>%\n  cal_plot_breaks(truth = default, estimate = .pred_yes) +\n  labs(title = \"XGBoost Probability Calibration\")\n\nlog_reg_cal\nxgb_cal\n\n# The feature importance plots show which variables have the strongest influence on default prediction. \n# In credit scoring, it's important that these align with domain knowledge. \n# The calibration plots show how well the predicted probabilities match the actual default rates.\n\n## Final Evaluation on Test Set\n\nNow let's evaluate our best model (XGBoost) on the held-out test set for an unbiased assessment of its performance.\n\n```{r}\n#| label: final-evaluation\n\n# Make predictions on the test set with the XGBoost model\ntest_results <- final_xgb_model %>%\n  predict(test_data) %>%\n  bind_cols(predict(final_xgb_model, test_data, type = \"prob\")) %>%\n  bind_cols(test_data %>% select(default, customer_id, credit_score))\n\n# Calculate performance metrics\ntest_metrics <- test_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\ncat(\"Final Test Set Performance Metrics:\\n\")\nprint(test_metrics)\n\n# Calculate AUC on test set\ntest_auc <- test_results %>%\n  roc_auc(truth = default, .pred_yes)\ncat(\"\\nTest Set ROC AUC: \", test_auc$.estimate, \"\\n\")\n\n# Create a gains table (commonly used in credit scoring)\ngains_table <- test_results %>%\n  mutate(risk_decile = ntile(.pred_yes, 10)) %>%\n  group_by(risk_decile) %>%\n  summarise(\n    total_accounts = n(),\n    defaults = sum(default == \"yes\"),\n    non_defaults = sum(default == \"no\"),\n    default_rate = mean(default == \"yes\"),\n    avg_score = mean(credit_score)) %>% \n  arrange(desc(default_rate)) %>% \n  mutate(\n    cumulative_defaults = cumsum(defaults),\n    pct_defaults_captured = cumulative_defaults / sum(defaults),\n    cumulative_accounts = cumsum(total_accounts),\n    pct_accounts = cumulative_accounts / sum(total_accounts),\n    lift = default_rate / (sum(defaults) / sum(total_accounts))\n  )\n\n# Display the gains table\ngains_table\n\n# Create a lift chart\nggplot(gains_table, aes(x = pct_accounts, y = lift)) +\n  geom_line() +\n  geom_point() +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Lift Chart\",\n       x = \"Percentage of Accounts\",\n       y = \"Lift\") +\n  theme_minimal()\n\n## Conclusion\n\nIn this post, we've demonstrated how to build a credit scoring model using the tidymodels framework. We covered:\n\n1. Creating a realistic credit dataset with domain-specific features\n2. Implementing a comprehensive feature engineering pipeline\n3. Training and tuning both traditional (logistic regression) and modern (XGBoost) models\n4. Evaluating model performance using industry-standard metrics\n5. Creating interpretable visualizations of model results\n\nThe tidymodels framework provides a consistent and modular approach to building machine learning models, making it easier to experiment with different algorithms and preprocessing steps while maintaining good statistical practices.\n","srcMarkdownNoYaml":"\n\nThe tidymodels framework provides a cohesive set of packages for modeling and machine learning in R, following tidyverse principles. In this post, we'll build a realistic credit scoring model using tidymodels.\n\nCredit scoring models are used by financial institutions to assess the creditworthiness of borrowers. These models predict the probability of default (failure to repay a loan) based on borrower characteristics and loan attributes. A good credit scoring model should effectively discriminate between high-risk and low-risk borrowers, be well-calibrated, and provide interpretable insights.\n\n## Required Packages\n\nFirst, let's load all the required packages for our analysis:\n\n```{r}\nlibrary(tidymodels)\nlibrary(xgboost)\nlibrary(vip)        # For variable importance\nlibrary(stringr)    # For string manipulation functions\nlibrary(probably)   # For calibration plots\nlibrary(ROSE)       # For imbalanced data visualization\nlibrary(corrplot)   # For correlation visualization\n```\n\n## Creating a Realistic Credit Scoring Dataset\n\nWe'll simulate a realistic credit dataset with common variables found in credit scoring models. The data will include demographic information, loan characteristics, and credit history variables.\n\n```{r}\nset.seed(123)\nn <- 10000  # Larger sample size for more realistic modeling\n\n# Create base features with realistic distributions\ndata <- tibble(\n  customer_id = paste0(\"CUS\", formatC(1:n, width = 6, format = \"d\", flag = \"0\")),\n  \n  # Demographics - with realistic age distribution for credit applicants\n  age = pmax(18, pmin(80, round(rnorm(n, 38, 13)))),\n  income = pmax(12000, round(rlnorm(n, log(52000), 0.8))),\n  employment_length = pmax(0, round(rexp(n, 1/6))),  # Exponential distribution for job tenure\n  home_ownership = sample(c(\"RENT\", \"MORTGAGE\", \"OWN\"), n, replace = TRUE, prob = c(0.45, 0.40, 0.15)),\n  \n  # Loan characteristics - with more realistic correlations\n  loan_amount = round(rlnorm(n, log(15000), 0.7) / 100) * 100,  # Log-normal for loan amounts\n  loan_term = sample(c(36, 60, 120), n, replace = TRUE, prob = c(0.6, 0.3, 0.1)),\n  \n  # Credit history - with more realistic distributions\n  credit_score = round(pmin(850, pmax(300, rnorm(n, 700, 90)))),\n  dti_ratio = pmax(0, pmin(65, rlnorm(n, log(20), 0.4))),  # Debt-to-income ratio\n  delinq_2yrs = rpois(n, 0.4),  # Number of delinquencies in past 2 years\n  inq_last_6mths = rpois(n, 0.7),  # Number of inquiries in last 6 months\n  open_acc = pmax(1, round(rnorm(n, 10, 4))),  # Number of open accounts\n  pub_rec = rbinom(n, 2, 0.06),  # Number of public records\n  revol_util = pmin(100, pmax(0, rnorm(n, 40, 20))),  # Revolving utilization\n  total_acc = pmax(open_acc, open_acc + round(rnorm(n, 8, 6)))  # Total accounts\n)\n\n# Add realistic correlations between variables\ndata <- data %>%\n  mutate(\n    # Interest rate depends on credit score and loan term\n    interest_rate = 25 - (credit_score - 300) * (15/550) + \n                    ifelse(loan_term == 36, -1, ifelse(loan_term == 60, 0, 1.5)) +\n                    rnorm(n, 0, 1.5),\n    \n    # Loan purpose with realistic probabilities\n    loan_purpose = sample(\n      c(\"debt_consolidation\", \"credit_card\", \"home_improvement\", \"major_purchase\", \"medical\", \"other\"), \n      n, replace = TRUE, \n      prob = c(0.45, 0.25, 0.10, 0.08, 0.07, 0.05)\n    ),\n    \n    # Add some derived features that have predictive power\n    payment_amount = (loan_amount * (interest_rate/100/12) * (1 + interest_rate/100/12)^loan_term) / \n                    ((1 + interest_rate/100/12)^loan_term - 1),\n    payment_to_income_ratio = (payment_amount * 12) / income\n  )\n\n# Create a more realistic default probability model with non-linear effects\nlogit_default <- with(data, {\n  -4.5 +  # Base intercept for ~10% default rate\n    -0.03 * (age - 18) +  # Age effect (stronger for younger borrowers)\n    -0.2 * log(income/10000) +  # Log-transformed income effect\n    -0.08 * employment_length +  # Employment length effect\n    ifelse(home_ownership == \"OWN\", -0.7, ifelse(home_ownership == \"MORTGAGE\", -0.3, 0)) +  # Home ownership\n    0.3 * log(loan_amount/1000) +  # Log-transformed loan amount\n    ifelse(loan_term == 36, 0, ifelse(loan_term == 60, 0.4, 0.8)) +  # Loan term\n    0.15 * interest_rate +  # Interest rate effect\n    ifelse(loan_purpose == \"debt_consolidation\", 0.5, \n           ifelse(loan_purpose == \"credit_card\", 0.4, \n                  ifelse(loan_purpose == \"medical\", 0.6, 0))) +  # Loan purpose\n    -0.01 * (credit_score - 300) +  # Credit score (stronger effect at lower scores)\n    0.06 * dti_ratio +  # DTI ratio effect\n    0.4 * delinq_2yrs +  # Delinquencies effect (stronger effect for first delinquency)\n    0.3 * inq_last_6mths +  # Inquiries effect\n    -0.1 * log(open_acc + 1) +  # Open accounts (log-transformed)\n    0.8 * pub_rec +  # Public records (strong effect)\n    0.02 * revol_util +  # Revolving utilization\n    1.2 * payment_to_income_ratio +  # Payment to income ratio (strong effect)\n    rnorm(n, 0, 0.8)  # Add some noise for realistic variation\n})\n\n# Generate default flag with realistic default rate\nprob_default <- plogis(logit_default)\ndata$default <- factor(rbinom(n, 1, prob_default), levels = c(0, 1), labels = c(\"no\", \"yes\"))\n\n# Check class distribution\ntable(data$default)\n```\n\n```{r}\nprop.table(table(data$default))\n```\n\n\n```{r}\n# Visualize the default rate\nggplot(data, aes(x = default, fill = default)) +\n  geom_bar(aes(y = ..prop.., group = 1)) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"Class Distribution in Credit Dataset\",\n       y = \"Percentage\") +\n  theme_minimal()\n```\n\n```{r}\n# Visualize the relationship between key variables and default rate\nggplot(data, aes(x = credit_score, y = as.numeric(default) - 1)) +\n  geom_smooth(method = \"loess\") +\n  labs(title = \"Default Rate by Credit Score\", \n       x = \"Credit Score\", y = \"Default Probability\") +\n  theme_minimal()\n```\n\n\n```{r}\n# Examine correlation between numeric predictors\ncredit_cors <- data %>%\n  select(age, income, employment_length, loan_amount, interest_rate, \n         credit_score, dti_ratio, delinq_2yrs, revol_util, payment_to_income_ratio) %>%\n  cor()\n\ncorrplot(credit_cors, method = \"circle\", type = \"upper\", \n         tl.col = \"black\", tl.srt = 45, tl.cex = 0.7)\n```\n\n\n## Data Splitting\n\nCredit default datasets are typically imbalanced, with defaults being the minority class. We'll use a stratified split to maintain the class distribution.\n\n```{r}\n# Create initial train/test split (80/20)\nset.seed(456)\ninitial_split <- initial_split(data, prop = 0.8, strata = default)\ntrain_data <- training(initial_split)\ntest_data <- testing(initial_split)\n\n# Create validation set from training data (75% train, 25% validation)\nset.seed(789)\nvalidation_split <- initial_split(train_data, prop = 0.75, strata = default)\n\n# Check class imbalance in training data\ntrain_class_counts <- table(training(validation_split)$default)\ntrain_class_props <- prop.table(train_class_counts)\n\ncat(\"Training data class distribution:\\n\")\nprint(train_class_counts)\ncat(\"\\nPercentage:\\n\")\nprint(train_class_props * 100)\n\n# Visualize class imbalance\nROSE::roc.curve(training(validation_split)$default == \"yes\", \n                training(validation_split)$credit_score,\n                plotit = TRUE,\n                main = \"ROC Curve for Credit Score Alone\")\n```\n\n## Feature Engineering and Preprocessing\n\nNow we'll create a comprehensive recipe with feature engineering steps relevant to credit scoring, including handling the class imbalance.\n\n```{r}\n# Examine the distributions of key variables\npar(mfrow = c(2, 2))\nhist(training(validation_split)$credit_score, \n     main = \"Credit Score Distribution\", xlab = \"Credit Score\")\n\nhist(training(validation_split)$dti_ratio, \n     main = \"DTI Ratio Distribution\", xlab = \"DTI Ratio\")\n\nhist(training(validation_split)$payment_to_income_ratio, \n     main = \"Payment to Income Ratio\", \n     xlab = \"Payment to Income Ratio\")\n\nhist(log(training(validation_split)$income), \n     main = \"Log Income Distribution\", xlab = \"Log Income\")\n\npar(mfrow = c(1, 1))\n```\n\n```{r}\n# Create a comprehensive recipe with domain knowledge\ncredit_recipe <- recipe(default ~ ., data = training(validation_split)) %>%\n  # Remove ID column\n  step_rm(customer_id) %>%\n  \n  # Convert categorical variables to factors\n  step_string2factor(home_ownership, loan_purpose) %>%\n  \n  # Create additional domain-specific features\n  step_mutate(\n    # We already have payment_to_income_ratio from data generation\n    # Add more credit risk indicators\n    credit_utilization = revol_util / 100,\n    acc_to_age_ratio = total_acc / age,\n    delinq_per_acc = ifelse(total_acc > 0, delinq_2yrs / total_acc, 0),\n    inq_rate = inq_last_6mths / (open_acc + 0.1),  # Inquiry rate relative to open accounts\n    term_factor = loan_term / 12,  # Term in years\n    log_income = log(income),  # Log transform income\n    log_loan = log(loan_amount),  # Log transform loan amount\n    payment_ratio = payment_amount / (income / 12),  # Monthly payment to monthly income\n    util_to_income = (revol_util / 100) * (dti_ratio / 100)  # Interaction term\n  ) %>%\n  \n  # Handle categorical variables\n  step_dummy(all_nominal_predictors()) %>%\n  \n  # Impute missing values (if any)\n  step_impute_median(all_numeric_predictors()) %>%\n  \n  # Transform highly skewed variables\n  step_YeoJohnson(income, loan_amount, payment_amount) %>%\n  \n  # Remove highly correlated predictors\n  step_corr(all_numeric_predictors(), threshold = 0.85) %>%\n  \n  # Normalize numeric predictors\n  step_normalize(all_numeric_predictors()) %>%\n  \n  # Remove zero-variance predictors\n  step_zv(all_predictors())\n\n# Prep the recipe to examine the steps\nprepped_recipe <- prep(credit_recipe)\nprepped_recipe\n\n# Check the transformed data\nrecipe_data <- bake(prepped_recipe, new_data = NULL)\nglimpse(recipe_data)\n\n# Verify class balance after SMOTE\ntable(recipe_data$default)\n```\n\nThe feature engineering steps above incorporate domain knowledge specific to credit risk modeling:\n\n- We create derived features that capture payment capacity, credit utilization, and borrower stability\n- We transform highly skewed variables using Yeo-Johnson transformations\n- We normalize all numeric predictors to put them on the same scale\n\n## Model Specification and Tuning\n\nFor credit scoring, we'll compare two models: a logistic regression model (commonly used in the financial industry for its interpretability) and an XGBoost model (for its predictive power). We'll tune both models using cross-validation.\n\n```{r}\n# Define the logistic regression model\nlog_reg_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\n# Create a logistic regression workflow\nlog_reg_workflow <- workflow() %>%\n  add_recipe(credit_recipe) %>%\n  add_model(log_reg_spec)\n\n# Define the tuning grid for logistic regression\nlog_reg_grid <- grid_regular(\n  penalty(range = c(-5, 0), trans = log10_trans()),\n  mixture(range = c(0, 1)),\n  levels = c(10, 5)\n)\n\n# Define the XGBoost model with tunable parameters\nxgb_spec <- boost_tree(\n  trees = tune(),\n  tree_depth = tune(),\n  min_n = tune(),\n  loss_reduction = tune(),\n  mtry = tune(),\n  learn_rate = tune()\n) %>%\n  set_engine(\"xgboost\", objective = \"binary:logistic\", scale_pos_weight = 5) %>%\n  set_mode(\"classification\")\n\n# Create an XGBoost workflow\nxgb_workflow <- workflow() %>%\n  add_recipe(credit_recipe) %>%\n  add_model(xgb_spec)\n\n# Define the tuning grid for XGBoost\nxgb_grid <- grid_latin_hypercube(\n  trees(range = c(100, 500)),\n  tree_depth(range = c(3, 10)),\n  min_n(range = c(2, 20)),\n  loss_reduction(range = c(0.001, 1.0)),\n  mtry(range = c(5, 20)),\n  learn_rate(range = c(-4, -1), trans = log10_trans()),\n  size = 15\n)\n\n# Create cross-validation folds with stratification\nset.seed(234)\ncv_folds <- vfold_cv(training(validation_split), v = 3, strata = default)\n\n# Define the metrics to evaluate\nclassification_metrics <- metric_set(\n  roc_auc,  # Area under the ROC curve\n  pr_auc,    # Area under the precision-recall curve\n)\n\n# Tune the logistic regression model\nset.seed(345)\nlog_reg_tuned <- tune_grid(\n  log_reg_workflow,\n  resamples = cv_folds,\n  grid = log_reg_grid,\n  metrics = classification_metrics,\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n# Tune the XGBoost model\nset.seed(456)\nxgb_tuned <- tune_grid(\n  xgb_workflow,\n  resamples = cv_folds,\n  grid = xgb_grid,\n  metrics = classification_metrics,\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n# Collect and visualize logistic regression tuning results\nlog_reg_results <- log_reg_tuned %>% collect_metrics()\nlog_reg_results %>% filter(.metric == \"roc_auc\") %>% arrange(desc(mean)) %>% head()\n```\n\nThe results above show how both models perform across different hyperparameter settings. XGBoost typically achieves higher predictive performance, while logistic regression offers better interpretability. For credit scoring applications, both aspects are important.\n\n## Finalizing and Evaluating the Models\n\nWe'll finalize both models using their best hyperparameters and evaluate them on the validation set.\n\n```{r}\n#| label: model-evaluation\n\n# Select best hyperparameters based on ROC AUC\nbest_log_reg_params <- select_best(log_reg_tuned, metric = \"roc_auc\")\nbest_xgb_params <- select_best(xgb_tuned, metric = \"roc_auc\")\n\n# Finalize workflows with best parameters\nfinal_log_reg_workflow <- log_reg_workflow %>%\n  finalize_workflow(best_log_reg_params)\n\nfinal_xgb_workflow <- xgb_workflow %>%\n  finalize_workflow(best_xgb_params)\n\n# Fit the final models on the full training data\nfinal_log_reg_model <- final_log_reg_workflow %>%\n  fit(data = training(validation_split))\n\nfinal_xgb_model <- final_xgb_workflow %>%\n  fit(data = training(validation_split))\n\n# Make predictions on the validation set with both models\nlog_reg_val_results <- final_log_reg_model %>%\n  predict(testing(validation_split)) %>%\n  bind_cols(predict(final_log_reg_model, testing(validation_split), type = \"prob\")) %>%\n  bind_cols(testing(validation_split) %>% select(default, customer_id))\n\nxgb_val_results <- final_xgb_model %>%\n  predict(testing(validation_split)) %>%\n  bind_cols(predict(final_xgb_model, testing(validation_split), type = \"prob\")) %>%\n  bind_cols(testing(validation_split) %>% select(default, customer_id))\n\n# Evaluate model performance on validation set\nlog_reg_val_metrics <- log_reg_val_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\nxgb_val_metrics <- xgb_val_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\ncat(\"Logistic Regression Validation Metrics:\\n\")\nprint(log_reg_val_metrics)\n\ncat(\"\\nXGBoost Validation Metrics:\\n\")\nprint(xgb_val_metrics)\n```\n\n## Feature Importance and Model Interpretation\n\nUnderstanding which features drive the predictions is crucial for credit scoring models.\n\n```{r}\n#| label: feature-importance\n#| fig-width: 10\n#| fig-height: 12\n\n# Extract feature importance from XGBoost model\nxgb_importance <- final_xgb_model %>%\n  extract_fit_parsnip() %>%\n  vip(num_features = 15) +\n  labs(title = \"XGBoost Feature Importance\")\n\nxgb_importance\n\n# Extract coefficients from logistic regression model\nlog_reg_importance <- final_log_reg_model %>%\n  extract_fit_parsnip() %>%\n  vip(num_features = 15) +\n  labs(title = \"Logistic Regression Coefficient Importance\")\n\nlog_reg_importance\n\n# Create calibration plots for both models\nlog_reg_cal <- log_reg_val_results %>%\n  cal_plot_breaks(truth = default, estimate = .pred_yes) +\n  labs(title = \"Logistic Regression Probability Calibration\")\n\nxgb_cal <- xgb_val_results %>%\n  cal_plot_breaks(truth = default, estimate = .pred_yes) +\n  labs(title = \"XGBoost Probability Calibration\")\n\nlog_reg_cal\nxgb_cal\n\n# The feature importance plots show which variables have the strongest influence on default prediction. \n# In credit scoring, it's important that these align with domain knowledge. \n# The calibration plots show how well the predicted probabilities match the actual default rates.\n\n## Final Evaluation on Test Set\n\nNow let's evaluate our best model (XGBoost) on the held-out test set for an unbiased assessment of its performance.\n\n```{r}\n#| label: final-evaluation\n\n# Make predictions on the test set with the XGBoost model\ntest_results <- final_xgb_model %>%\n  predict(test_data) %>%\n  bind_cols(predict(final_xgb_model, test_data, type = \"prob\")) %>%\n  bind_cols(test_data %>% select(default, customer_id, credit_score))\n\n# Calculate performance metrics\ntest_metrics <- test_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\ncat(\"Final Test Set Performance Metrics:\\n\")\nprint(test_metrics)\n\n# Calculate AUC on test set\ntest_auc <- test_results %>%\n  roc_auc(truth = default, .pred_yes)\ncat(\"\\nTest Set ROC AUC: \", test_auc$.estimate, \"\\n\")\n\n# Create a gains table (commonly used in credit scoring)\ngains_table <- test_results %>%\n  mutate(risk_decile = ntile(.pred_yes, 10)) %>%\n  group_by(risk_decile) %>%\n  summarise(\n    total_accounts = n(),\n    defaults = sum(default == \"yes\"),\n    non_defaults = sum(default == \"no\"),\n    default_rate = mean(default == \"yes\"),\n    avg_score = mean(credit_score)) %>% \n  arrange(desc(default_rate)) %>% \n  mutate(\n    cumulative_defaults = cumsum(defaults),\n    pct_defaults_captured = cumulative_defaults / sum(defaults),\n    cumulative_accounts = cumsum(total_accounts),\n    pct_accounts = cumulative_accounts / sum(total_accounts),\n    lift = default_rate / (sum(defaults) / sum(total_accounts))\n  )\n\n# Display the gains table\ngains_table\n\n# Create a lift chart\nggplot(gains_table, aes(x = pct_accounts, y = lift)) +\n  geom_line() +\n  geom_point() +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Lift Chart\",\n       x = \"Percentage of Accounts\",\n       y = \"Lift\") +\n  theme_minimal()\n\n## Conclusion\n\nIn this post, we've demonstrated how to build a credit scoring model using the tidymodels framework. We covered:\n\n1. Creating a realistic credit dataset with domain-specific features\n2. Implementing a comprehensive feature engineering pipeline\n3. Training and tuning both traditional (logistic regression) and modern (XGBoost) models\n4. Evaluating model performance using industry-standard metrics\n5. Creating interpretable visualizations of model results\n\nThe tidymodels framework provides a consistent and modular approach to building machine learning models, making it easier to experiment with different algorithms and preprocessing steps while maintaining good statistical practices.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"zenburn","toc":true,"css":["../styles.css"],"output-file":"modeling-with-tidymodels.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","editor":"source","theme":"sketchy","code-copy":true,"title":"Building Models in R with tidymodels","date":"2024-10-12","categories":["R","Machine Learning","tidymodels"],"image":"../images/tidymodels.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
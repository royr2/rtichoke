{
  "hash": "9e1a885c4549329016d11ebba024a656",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Portfolio Optimization Using PSO\"\ndate: \"2023-05-17\"\ncategories: [R, Finance, Optimization]\nimage: \"../images/portfolio_optimisation.png\"\nexecute:\n  echo: true\n  warning: false\n  message: false\n  eval: true\n---\n\n\n\n\nPortfolio optimization represents a critical task in investment management, where the goal involves allocating capital across different assets to maximize returns while controlling risk. This post explores how to use Particle Swarm Optimization (PSO) to perform mean-variance portfolio optimization with various constraints.\n\n1. For additional information on mean-variance optimization and the CAPM model, refer to this [paper](http://www.columbia.edu/~mh2078/FoundationsFE/MeanVariance-CAPM.pdf).\n\n2. For additional information on particle swarm optimisation, refer to [this post](/posts/building-particle-swarm-optimizer.qmd) on \n\n## Libraries\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(pso)       # For PSO implementation (provides psoptim function)\nlibrary(ggplot2)   # For data visualization\nlibrary(dplyr)     # For data manipulation and transformation\nlibrary(quantmod)  # For downloading financial data\nlibrary(tidyr)     # For reshaping data (pivot_wider, gather functions)\nlibrary(plotly)    # For creating interactive 3D visualizations\n```\n:::\n\n\n\n\n## Data Collection\n\nThe first step is to gather historical price data to calculate returns and risk metrics.\n\n### Getting Stock Tickers\n\nThis post uses stocks from the NIFTY50 index, which includes the 50 largest Indian companies by market capitalisation:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read ticker list from NSE (National Stock Exchange of India) website\nticker_list <- read.csv(\"https://raw.githubusercontent.com/royr2/datasets/refs/heads/main/ind_nifty50list.csv\")\n\n# View the first few rows \nhead(ticker_list[,1:3], 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                Company.Name           Industry     Symbol\n1                     Adani Enterprises Ltd.    Metals & Mining   ADANIENT\n2 Adani Ports and Special Economic Zone Ltd.           Services ADANIPORTS\n3           Apollo Hospitals Enterprise Ltd.         Healthcare APOLLOHOSP\n4                          Asian Paints Ltd.  Consumer Durables ASIANPAINT\n5                             Axis Bank Ltd. Financial Services   AXISBANK\n```\n\n\n:::\n:::\n\n\n\n\n### Downloading Historical Price Data\n\nThe next step involves downloading historical price data for these stocks using the `quantmod` package, which provides an interface to Yahoo Finance:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Append \".NS\" to tickers for Yahoo Finance format (NS = National Stock Exchange)\ntickers <- paste0(ticker_list$Symbol, \".NS\")\ntickers <- tickers[!tickers %in% c(\"ETERNAL.NS\", \"JIOFIN.NS\")]\n\n# Initialize empty dataframe to store all ticker data\nticker_df <- data.frame()\n\n# Create a progress bar to monitor the download process\n# pb <- txtProgressBar(min = 1, max = length(tickers), style = 3)\n\n# Loop through each ticker and download its historical data\nfor(nms in tickers){\n  # Download data from Yahoo Finance\n  df <- getSymbols(Symbols = nms, verbose = FALSE, auto.assign = FALSE)\n  \n  # Rename columns for clarity\n  colnames(df) <- c(\"open\", \"high\", \"low\", \"close\", \"volume\", \"adjusted\")\n  df$date = rownames(df)\n  \n  # Convert to dataframe and add ticker and date information\n  df <- data.frame(df)\n  df$ticker <- nms\n  df$date <- rownames(df)\n  \n  # Append to the main dataframe\n  ticker_df <- rbind(ticker_df, df)\n  \n  Sys.sleep(0.2)\n  \n  # Update progress bar\n  # setTxtProgressBar(pb, which(tickers == nms))\n}\n\n# Reshape data to wide format with dates as rows and tickers as columns\n# This format facilitates the calculation of returns across all stocks\nprices_df <- pivot_wider(data = ticker_df, id_cols = \"date\", names_from = \"ticker\", values_from = \"close\")\n\n# Remove rows with missing values to ensure complete data\nprices_df <- na.omit(prices_df)\n\n# Check the date range of our data\nrange(prices_df$date)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2017-11-17\" \"2025-06-20\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check dimensions (number of trading days Ã— number of stocks + date column)\ndim(prices_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1874   49\n```\n\n\n:::\n:::\n\n\n\n\n### Visualizing the Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot closing prices for metal stocks\nprices_df %>% \n  # Convert from wide to long format for easier plotting with ggplot2\n  pivot_longer(-date, names_to = \"ticker\", values_to = \"price\") %>% \n  \n  # Attach industry information from our original ticker list\n  left_join(ticker_list %>% \n              mutate(ticker = paste0(Symbol, \".NS\")) %>% \n              select(ticker, industry = Industry),\n            by = \"ticker\") %>% \n  \n  # Convert date strings to Date objects\n  mutate(date = as.Date(date)) %>% \n  \n  # Filter to show only metal industry stocks for clarity\n  filter(stringr::str_detect(tolower(industry), \"metal\")) %>% \n  \n  # Create the line plot\n  ggplot(aes(x = date, y = price, color = ticker)) + \n  geom_line(linewidth = 0.8) + \n  theme_minimal() + \n  scale_color_brewer(palette = \"RdBu\") +  # Use a color-blind friendly palette\n  labs(title = \"Closing Prices\", \n       subtitle = \"Nifty 50 metal stocks\",\n       x = \"Date\", \n       y = \"Closing Price\") + \n  theme(legend.position = \"top\", \n        legend.title = element_text(colour = \"transparent\"), \n        axis.title.x = element_text(face = \"bold\"), \n        axis.title.y = element_text(face = \"bold\"))\n```\n\n::: {.cell-output-display}\n![](portfolio_optimisation_pso_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\nThe visualization demonstrates the price movements of metal stocks over time. The data reveals periods of both correlation and divergence between different stocks, highlighting the importance of diversification in portfolio construction.\n\n### Calculating Returns\n\nFor portfolio optimization, we need to work with returns rather than prices. Returns better represent the investment performance and have more desirable statistical properties (like stationarity):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate daily returns for all stocks\n# Formula: (Price_today / Price_yesterday) - 1\nreturns_df <- apply(prices_df[,-1], 2, function(vec){\n  ret <- vec/lag(vec) - 1  # Simple returns calculation\n  return(ret)\n})\n\n# Convert to dataframe for easier manipulation\nreturns_df <- as.data.frame(returns_df)\n\n# Remove first row which contains NA values (no previous day to calculate return)\nreturns_df <- returns_df[-1,]  \n\n# Pre-compute average returns and covariance matrix for optimization\n# These constitute key inputs to the mean-variance optimization\nmean_returns <- sapply(returns_df, mean)  # Expected returns\ncov_mat <- cov(returns_df)  # Risk (covariance) matrix\n```\n:::\n\n\n\n\nThe mean returns represent expectations for each asset's performance, while the covariance matrix captures both the individual volatilities and the relationships between assets. These serve as inputs to the optimization process.\n\n## Portfolio Optimization Framework\n\n### Objective Function\n\nIn mean-variance optimisation the objective function, which defines the optimization target balances three key components:\n\n1. **Expected returns (reward)**: The weighted average of expected returns for each asset\n2. **Portfolio variance (risk)**: A measure of the portfolio's volatility, calculated using the covariance matrix\n3. **Risk aversion parameter**: Controls the trade-off between risk and return (higher values prioritize risk reduction)\n\nThe implementation also incorporates constraints through penalty terms:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobj_func <- function(wts, \n                     risk_av = 10,  # Risk aversion parameter\n                     lambda1 = 10,  # Penalty weight for full investment constraint\n                     lambda2 = 1e2,  # Reserved for additional constraints\n                     ret_vec, cov_mat){\n  \n  # Calculate expected portfolio return (weighted average of asset returns)\n  port_returns <- ret_vec %*% wts\n  \n  # Calculate portfolio risk (quadratic form using covariance matrix)\n  port_risk <- t(wts) %*% cov_mat %*% wts\n  \n  # Mean-variance utility function: return - risk_aversion * risk\n  # This is the core Markowitz portfolio optimization formula\n  obj <- port_returns - risk_av * port_risk\n  \n  # Add penalty for violating the full investment constraint (sum of weights = 1)\n  # The squared term ensures the penalty increases quadratically with violation size\n  obj <- obj - lambda1 * (sum(wts) - 1)^2\n    # Return negative value since PSO minimizes by default, but the goal is to maximize\n  # the objective (higher returns, lower risk)\n  return(-obj)\n}\n```\n:::\n\n\n\n\nThis objective function implements the classic mean-variance utility with a quadratic penalty for the full investment constraint. The risk aversion parameter allows us to move along the efficient frontier to find portfolios with different risk-return profiles.\n\n## Two-Asset Example\n\nBefore tackling the full portfolio optimization problem, this section begins with a simple two-asset example. This approach helps visualize how PSO works and validates the methodology:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use only the first two assets for this example\n# Calculate their average returns and covariance matrix\nmean_returns_small <- apply(returns_df[,1:2], 2, mean)\ncov_mat_small <- cov(returns_df[,1:2])\n\n# Define a custom PSO optimizer function to track the optimization process\npso_optim <- function(obj_func,\n                      c1 = 0.05,      # Cognitive parameter (personal best influence)\n                      c2 = 0.05,      # Social parameter (global best influence)\n                      w = 0.8,        # Inertia weight (controls momentum)\n                      init_fact = 0.1, # Initial velocity factor\n                      n_particles = 20, # Number of particles in the swarm\n                      n_dim = 2,       # Dimensionality (number of assets)\n                      n_iter = 50,     # Maximum iterations\n                      upper = 1,       # Upper bound for weights\n                      lower = 0,       # Lower bound for weights (no short selling)\n                      n_avg = 10,      # Number of iterations for averaging\n                      ...){\n  \n  # Initialize particle positions randomly within bounds\n  X <- matrix(runif(n_particles * n_dim), nrow = n_particles)\n  X <- X * (upper - lower) + lower  # Scale to fit within bounds\n  \n  # Initialize particle velocities (movement speeds)\n  dX <- matrix(runif(n_particles * n_dim) * init_fact, ncol = n_dim)\n  dX <- dX * (upper - lower) + lower\n  \n  # Initialize personal best positions and objective values\n  pbest <- X  # Each particle's best position so far\n  pbest_obj <- apply(X, 1, obj_func, ...)  # Objective value at personal best\n  \n  # Initialize global best position and objective value\n  gbest <- pbest[which.min(pbest_obj),]  # Best position across all particles\n  gbest_obj <- min(pbest_obj)  # Best objective value found\n  \n  # Store initial positions for visualization\n  loc_df <- data.frame(X, iter = 0, obj = pbest_obj)\n  iter <- 1\n  \n  # Main PSO loop\n  while(iter < n_iter){\n    \n    # Update velocities using PSO formula:\n    # New velocity = inertia + cognitive component + social component\n    dX <- w * dX +                         # Inertia (continue in same direction)\n          c1*runif(1)*(pbest - X) +        # Pull toward personal best\n          c2*runif(1)*t(gbest - t(X))      # Pull toward global best\n    \n    # Update positions based on velocities\n    X <- X + dX\n    \n    # Evaluate objective function at new positions\n    obj <- apply(X, 1, obj_func, ...)\n    \n    # Update personal bests if new positions are better\n    idx <- which(obj <= pbest_obj)\n    pbest[idx,] <- X[idx,]\n    pbest_obj[idx] <- obj[idx]\n    \n    # Update global best if a better solution is found\n    idx <- which.min(pbest_obj)\n    gbest <- pbest[idx,]\n    gbest_obj <- min(pbest_obj)\n    \n    # Store current state for visualization\n    iter <- iter + 1\n    loc_df <- rbind(loc_df, data.frame(X, iter = iter, obj = pbest_obj))\n  }\n  \n  # Return optimization results\n  lst <- list(X = loc_df,          # All particle positions throughout optimization\n              obj = gbest_obj,     # Best objective value found\n              obj_loc = gbest)     # Weights that achieved the best objective\n  return(lst)\n}\n\n# Run the optimization for our two-asset portfolio\nout <- pso_optim(obj_func,\n                 ret_vec = mean_returns_small,  # Expected returns\n                 cov_mat = cov_mat_small,       # Covariance matrix\n                 lambda1 = 10, risk_av = 100,    # Constraint and risk parameters\n                 n_particles = 100,              # Use 100 particles for better coverage\n                 n_dim = 2,                      # Two-asset portfolio\n                 n_iter = 200,                   # Run for 200 iterations\n                 upper = 1, lower = 0,           # Bounds for weights\n                 c1 = 0.02, c2 = 0.02,           # Lower influence parameters for stability\n                 w = 0.05, init_fact = 0.01)     # Low inertia for better convergence\n\n# Verify that the weights sum to approximately 1 (full investment constraint)\nsum(out$obj_loc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9906321\n```\n\n\n:::\n:::\n\n\n\n\nIn this implementation, the tracking of all particle movements throughout the optimization process occurs. This enables visualization of how the swarm converges toward the optimal solution.\n\n### Visualizing the Optimization Process\n\nOne advantage of starting with a two-asset example is the ability to visualize the entire search space and observe how the PSO algorithm explores it. The following creates a 3D visualization of the objective function landscape and the path each particle took during optimization:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a fine grid of points covering the feasible region (all possible weight combinations)\ngrid <- expand.grid(x = seq(0, 1, by = 0.01),  # First asset weight from 0 to 1\n                    y = seq(0, 1, by = 0.01))   # Second asset weight from 0 to 1\n\n# Evaluate the objective function at each grid point to create the landscape\ngrid$obj <- apply(grid, 1, obj_func, \n                  ret_vec = mean_returns_small, \n                  cov_mat = cov_mat_small, \n                  lambda1 = 10, risk_av = 100)\n\n# Create an interactive 3D plot showing both the objective function surface\n# and the particle trajectories throughout the optimization\np <- plot_ly() %>% \n  # Add the objective function surface as a mesh\n  add_mesh(data = grid, x = ~x, y = ~y, z = ~obj, \n           inherit = FALSE, color = \"red\") %>% \n  \n  # Add particles as markers, colored by iteration to show progression\n  add_markers(data = out$X, x = ~X1, y = ~X2, z = ~obj, \n              color = ~ iter, inherit = FALSE, \n              marker = list(size = 2))\n```\n:::\n\n\n\nThis visualization demonstrates:\n\n1. The objective function landscape as a 3D surface\n2. The particles (small dots) exploring the search space\n3. How the swarm converges toward the optimal solution over iterations (color gradient)\n\nThe concentration of particles in certain regions indicates where the algorithm found promising solutions. The global best solution represents where the particles ultimately converge.\n\n## Multi-Asset Portfolio Optimization\n\nTo scale the problem to multiple assets, instead of using the custom PSO implementation, this section leverages the `psoptim` function from the `pso` package:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the number of stocks in the dataset\nn_stocks <- ncol(returns_df)\n\n# Run the PSO optimization for the full portfolio\nopt <- psoptim(\n  # Initial particle positions (starting with equal weights)\n  par = rep(0, n_stocks),\n  \n  # Objective function to minimize\n  fn = obj_func,\n  \n  # Pass the expected returns and covariance matrix\n  ret_vec = mean_returns, \n  cov_mat = cov_mat,\n  \n  # Set constraint parameters\n  lambda1 = 10,  # Weight for full investment constraint\n  risk_av = 1000,  # Higher risk aversion for a more conservative portfolio\n  \n  # Set bounds for weights (no short selling allowed)\n  lower = rep(0, n_stocks),\n  upper = rep(1, n_stocks),\n  \n  # Configure the PSO algorithm\n  control = list(\n    maxit = 200,          # Maximum iterations\n    s = 100,               # Swarm size (number of particles)\n    maxit.stagnate = 500   # Stop if no improvement after this many iterations\n  )\n)\n\n# Calculate and display the expected return of the optimized portfolio\npaste(\"Portfolio returns:\", round(opt$par %*% mean_returns, 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Portfolio returns: 0.00061\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate and display the standard deviation (risk) of the optimized portfolio\npaste(\"Portfolio Std dev:\", round(sqrt(opt$par %*% cov_mat %*% opt$par), 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Portfolio Std dev: 0.00879\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Verify that the weights sum to approximately 1 (full investment constraint)\nsum(opt$par)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9950411\n```\n\n\n:::\n:::\n\n\n\n\n## Adding Tracking Error Constraint\n\nTracking error measures how closely a portfolio follows a benchmark. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define benchmark portfolio (equally weighted across all stocks)\nbench_wts <- rep(1/n_stocks, n_stocks)\n\n# Calculate the time series of benchmark returns\nbench_returns <- as.matrix(returns_df) %*% t(t(bench_wts))\n\n# Create a new objective function that includes tracking error\nobj_func_TE <- function(wts,  \n                        risk_av = 10,     # Risk aversion parameter\n                        lambda1 = 10,    # Full investment constraint weight\n                        lambda2 = 50,    # Tracking error constraint weight\n                        ret_vec, cov_mat){\n  \n  # Calculate portfolio metrics\n  port_returns <- ret_vec %*% wts                      # Expected portfolio return\n  port_risk <- t(wts) %*% cov_mat %*% wts             # Portfolio variance\n  port_returns_ts <- as.matrix(returns_df) %*% t(t(wts))  # Time series of portfolio returns\n  \n  # Original mean-variance objective\n  obj <- port_returns - risk_av * port_risk\n  \n  # Full investment constraint (weights sum to 1)\n  obj <- obj - lambda1 * (sum(wts) - 1)^2\n  \n  # Tracking error constraint (penalize deviation from benchmark)\n  # Tracking error is measured as the standard deviation of the difference\n  # between portfolio returns and benchmark returns\n  obj <- obj - lambda2 * sd(port_returns_ts - bench_returns)\n  \n  return(-obj)  # Return negative for minimization\n}\n\n# Run optimization with the tracking error constraint\nopt <- psoptim(\n  # Initial particle positions\n  par = rep(0, n_stocks),\n  \n  # Use our new objective function with tracking error\n  fn = obj_func_TE,\n  \n  # Pass the expected returns and covariance matrix\n  ret_vec = mean_returns, \n  cov_mat = cov_mat,\n  \n  # Set constraint parameters\n  lambda1 = 10,    # Weight for full investment constraint\n  risk_av = 1000,  # Risk aversion parameter\n  \n  # Set bounds for weights\n  lower = rep(0, n_stocks),\n  upper = rep(1, n_stocks),\n  \n  # Configure the PSO algorithm\n  control = list(\n    maxit = 200,          # Maximum iterations\n    s = 100,               # Swarm size\n    maxit.stagnate = 500   # Stop if no improvement after this many iterations\n  )\n)\n\n# Calculate and display the expected return of the optimized portfolio\npaste(\"Portfolio returns:\", round(opt$par %*% mean_returns, 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Portfolio returns: 0.00075\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate and display the standard deviation (risk) of the optimized portfolio\npaste(\"Portfolio Std dev:\", round(sqrt(opt$par %*% cov_mat %*% opt$par), 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Portfolio Std dev: 0.01087\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Verify that the weights sum to approximately 1\nsum(opt$par)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9938126\n```\n\n\n:::\n:::\n\n\n\n\nAdding the tracking error constraint, not only balances risk and return but also tracks the performance of an equally-weighted benchmark. The `lambda2` parameter controls the closeness of benchmark tracking - higher values result in portfolios that more closely resemble the benchmark.\n\n## Advantages and Limitations of PSO\n\n### Advantages:\n\n1. **Flexibility**: PSO can handle non-convex, non-differentiable objective functions, making it suitable for complex portfolio constraints that traditional optimizers struggle with\n\n2. **Simplicity**: The algorithm is intuitive and relatively easy to implement compared to other global optimization techniques\n\n3. **Constraints**: Various constraints can be easily incorporated through penalty functions without reformulating the entire problem\n\n4. **Global Search**: PSO explores the search space more thoroughly and is less likely to get stuck in local optima compared to gradient-based methods\n\n5. **Parallelization**: The algorithm is naturally parallelizable, as particles can be evaluated independently\n\n### Limitations:\n\n1. **Variability**: Results can vary between runs due to the stochastic nature of the algorithm, potentially leading to inconsistent portfolio recommendations\n\n2. **Parameter Tuning**: Performance significantly depends on parameters like inertia weight and acceleration coefficients, which may require careful tuning\n\n3. **Convergence**: There's no mathematical guarantee of convergence to the global optimum, unlike some convex optimization methods\n\n4. **Computational Cost**: Can be computationally intensive for high-dimensional problems with many assets\n\n5. **Constraint Handling**: While flexible, the penalty function approach may not always satisfy constraints exactly\n\n## Practical Applications\n\nPSO-based portfolio optimization proves particularly valuable in scenarios where:\n\n- Traditional quadratic programming approaches fail due to complex constraints\n- The objective function includes non-linear terms like higher moments (skewness, kurtosis)\n- Multiple competing objectives need to be balanced\n- The portfolio needs to satisfy regulatory or client-specific constraints\n\nThe approach demonstrated in this post can be extended to include additional constraints such as:\n\n- Sector or industry exposure limits\n- Maximum position sizes\n- Turnover or transaction cost constraints\n- Risk factor exposures and limits\n- Cardinality constraints (limiting the number of assets)",
    "supporting": [
      "portfolio_optimisation_pso_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
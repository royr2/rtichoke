{
  "hash": "b4a8d568e210d70c24b7774b713341a6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tutorial: Generating Correlated Random Numbers in R Using Matrix Methods\"\ndate: \"2024-03-19\"\ncategories: [R, Statistics, Simulation]\nimage: \"../images/correlated.png\"\nexecute:\n  echo: true\n  warning: false\n  message: false\n  eval: true\n---\n\n\n\n## Introduction\n\nThe generation of random data with specified correlation patterns represents a fundamental requirement in statistical simulation and algorithm testing. This tutorial provides a comprehensive methodology for creating correlated random numbers in R using matrix-based approaches, with particular emphasis on the Cholesky decomposition method. The techniques presented enable the development of realistic synthetic datasets with precisely controlled correlation structures, essential for robust statistical analysis and model validation.\n\n## The Cholesky Decomposition Method: A Four-Step Implementation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 1. Define your target correlation matrix\ncor_mat <- matrix(c(1, 0.3, \n                   0.3, 1), nrow = 2, byrow = TRUE)\n\n# 2. Apply Cholesky decomposition\nchol_mat <- chol(cor_mat)\n\n# 3. Generate uncorrelated random numbers\nold_random <- matrix(rnorm(2000), ncol = 2)\n\n# 4. Transform to create correlation\nnew_random <- old_random %*% chol_mat\n\n# Verify the correlation\ncor(new_random)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]\n[1,] 1.0000000 0.3112079\n[2,] 0.3112079 1.0000000\n```\n\n\n:::\n:::\n\n\n\nThe resulting `new_random` matrix contains values exhibiting approximately the target correlation structure. This technique employs Cholesky decomposition to construct a transformation matrix that induces the desired correlation when applied to uncorrelated input data.\n\n## Critical Implementation Considerations and Common Pitfalls\n\n### Input Data Independence Requirement\n\nThe input data must demonstrate statistical independence for the Cholesky method to function correctly. Pre-existing correlations in the input data compromise the method's ability to achieve target correlation structures:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# What happens with already correlated input?\nsimulate_correlation <- function(input_correlation, target = 0.3) {\n  results <- replicate(1000, {\n    # Create input with specified correlation\n    x <- rnorm(1000)\n    y <- input_correlation * x + rnorm(1000, sd = sqrt(1 - input_correlation^2))\n    \n    # Apply our method\n    old_random <- cbind(x, y)\n    chol_mat <- chol(matrix(c(1, target, target, 1), ncol = 2))\n    new_random <- old_random %*% chol_mat\n    \n    # Return resulting correlation\n    cor(new_random)[1,2]\n  })\n  return(results)\n}\n\n# Compare results with different input correlations\npar(mfrow = c(1, 2))\nhist(simulate_correlation(0.8), main = \"Starting with Correlated Data\",\n     xlim = c(0, 1), col = \"salmon\")\nhist(simulate_correlation(0.001), main = \"Starting with Random Data\",     xlim = c(0, 1), col = \"lightblue\")\n```\n\n::: {.cell-output-display}\n![](generating-correlated-random-numbers_files/figure-html/correlation-comparison-1.png){width=672}\n:::\n:::\n\n\n\nWhen input data contains pre-existing correlation patterns, the Cholesky method cannot effectively override these relationships to establish the desired target correlation structure.\n\n### Distribution Consistency Requirement\n\nOptimal results require consistent probability distributions across all variables in the transformation:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Different distributions cause problems\nset.seed(123)\nx1 <- rchisq(1000, df = 3)  # Chi-squared (skewed)\ny1 <- rnorm(1000)           # Normal (symmetric)\nold_mixed <- cbind(x1, y1)\n\n# Same distribution works better\nx2 <- rchisq(1000, df = 3)\ny2 <- rchisq(1000, df = 3)\nold_same <- cbind(x2, y2)\n\n# Apply the same transformation to both\nchol_mat <- chol(matrix(c(1, 0.7, 0.7, 1), ncol = 2))\nnew_mixed <- old_mixed %*% chol_mat\nnew_same <- old_same %*% chol_mat\n\n# Compare results\ncat(\"Target correlation: 0.7\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTarget correlation: 0.7\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mixed distributions result:\", round(cor(new_mixed)[1,2], 3), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMixed distributions result: 0.915 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Same distribution result:\", round(cor(new_same)[1,2], 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSame distribution result: 0.699\n```\n\n\n:::\n:::\n\n\n\nThe combination of different probability distributions (such as normal and chi-squared) can result in unexpected correlation patterns following the Cholesky transformation.\n\n### Distribution Property Preservation Challenges\n\nThe Cholesky transformation may fundamentally alter the statistical properties of the original data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Original positive-only distribution\nx <- rchisq(1000, df = 3)  # Always positive\ny <- rchisq(1000, df = 3)  # Always positive\nold_random <- cbind(x, y)\n\n# Apply negative correlation\nchol_mat <- chol(matrix(c(1, -0.7, -0.7, 1), ncol = 2))\nnew_random <- old_random %*% chol_mat\n\n# Check what happened\ncat(\"Original data range:\", round(range(old_random), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOriginal data range: 0.02 19.93 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Transformed data range:\", round(range(new_random), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTransformed data range: -12.81 19.93 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative values in result:\", sum(new_random < 0), \"out of\", length(new_random))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative values in result: 488 out of 2000\n```\n\n\n:::\n:::\n\n\n\nThe Cholesky transformation can fundamentally modify data characteristics, such as introducing negative values into previously positive-only distributions, thereby altering the fundamental nature of the data.\n\n## Alternative Implementation: The mvtnorm Package Approach\n\nFor practical applications requiring efficient implementation, the `mvtnorm` package provides a streamlined solution for generating multivariate normal distributions with specified correlation structures:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the package\nlibrary(mvtnorm)\n\n# Define means and covariance matrix\nmeans <- c(10, 20)  # Mean for each variable\nsigma <- matrix(c(4, 2,   # Covariance matrix\n                  2, 3), ncol = 2)\n\n# See the implied correlation\ncov2cor(sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]\n[1,] 1.0000000 0.5773503\n[2,] 0.5773503 1.0000000\n```\n\n\n:::\n\n```{.r .cell-code}\n# Generate correlated normal data in one step\nx <- rmvnorm(n = 1000, mean = means, sigma = sigma)\n\n# Verify the result\nround(cor(x), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1]  [,2]\n[1,] 1.000 0.613\n[2,] 0.613 1.000\n```\n\n\n:::\n:::\n\n\n\n## Methodological Selection Criteria\n\n### Cholesky Decomposition Method\n\n**Recommended Applications:**\n- Educational contexts requiring understanding of underlying mathematical principles\n- Non-normal distribution requirements\n- Custom correlation structure development\n- Theoretical research applications\n\n### mvtnorm Package Implementation\n\n**Recommended Applications:**\n- Production environments requiring rapid multivariate normal data generation\n- Scenarios demanding precise control over means and variance parameters\n- High-dimensional variable systems\n- Operational analytical workflows\n\n## Key Takeaways\n\nThis tutorial has demonstrated comprehensive methodologies for generating correlated random numbers in R. The essential insights include:\n\n- **Cholesky decomposition provides a mathematical foundation** for transforming uncorrelated data into correlated structures through matrix operations\n- **Input data independence is critical** for successful correlation induction; pre-existing correlations compromise the transformation effectiveness\n- **Distribution consistency across variables ensures optimal results** and prevents unexpected correlation artifacts\n- **The transformation process can alter fundamental data properties**, requiring careful consideration of distributional characteristics\n- **The mvtnorm package offers production-ready solutions** for multivariate normal data generation with specified correlation structures\n- **Method selection depends on specific requirements**: Cholesky for educational and custom applications, mvtnorm for operational efficiency\n\nThese techniques form the foundation for advanced statistical simulation, enabling the creation of realistic synthetic datasets essential for robust model validation and algorithm testing across diverse analytical domains.",
    "supporting": [
      "generating-correlated-random-numbers_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
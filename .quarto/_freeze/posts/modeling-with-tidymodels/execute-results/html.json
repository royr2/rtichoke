{
  "hash": "7aeaa4d4347242bcbb764cf197c189a8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Building Models in R with tidymodels\"\ndate: \"2024-10-12\"\ncategories: [R, Machine Learning, tidymodels]\nimage: \"../images/tidymodels.png\"\nexecute:\n  echo: true\n  warning: false\n  message: false\n  eval: true\n---\n\n\n\nThe tidymodels framework provides a cohesive set of packages for modeling and machine learning in R, following tidyverse principles. In this post, we'll build a realistic credit scoring model using tidymodels.\n\nCredit scoring models are used by financial institutions to assess the creditworthiness of borrowers. These models predict the probability of default (failure to repay a loan) based on borrower characteristics and loan attributes. A good credit scoring model should effectively discriminate between high-risk and low-risk borrowers, be well-calibrated, and provide interpretable insights.\n\n## Required Packages\n\nFirst, let's load all the required packages for our analysis:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(xgboost)\nlibrary(vip)        # For variable importance\nlibrary(stringr)    # For string manipulation functions\nlibrary(probably)   # For calibration plots\nlibrary(ROSE)       # For imbalanced data visualization\nlibrary(corrplot)   # For correlation visualization\n```\n:::\n\n\n\n## Synthetic Data Generation\n\nThis tutorial uses a simulated credit dataset incorporating realistic variable distributions commonly encountered in credit scoring applications. The synthetic data includes demographic information, loan characteristics, and credit history variables with appropriate statistical relationships.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- 10000  # Larger sample size for more realistic modeling\n\n# Create base features with realistic distributions\ndata <- tibble(\n  customer_id = paste0(\"CUS\", formatC(1:n, width = 6, format = \"d\", flag = \"0\")),\n  \n  # Demographics - with realistic age distribution for credit applicants\n  age = pmax(18, pmin(80, round(rnorm(n, 38, 13)))),\n  income = pmax(12000, round(rlnorm(n, log(52000), 0.8))),\n  employment_length = pmax(0, round(rexp(n, 1/6))),  # Exponential distribution for job tenure\n  home_ownership = sample(c(\"RENT\", \"MORTGAGE\", \"OWN\"), n, replace = TRUE, prob = c(0.45, 0.40, 0.15)),\n  \n  # Loan characteristics - with more realistic correlations\n  loan_amount = round(rlnorm(n, log(15000), 0.7) / 100) * 100,  # Log-normal for loan amounts\n  loan_term = sample(c(36, 60, 120), n, replace = TRUE, prob = c(0.6, 0.3, 0.1)),\n  \n  # Credit history - with more realistic distributions\n  credit_score = round(pmin(850, pmax(300, rnorm(n, 700, 90)))),\n  dti_ratio = pmax(0, pmin(65, rlnorm(n, log(20), 0.4))),  # Debt-to-income ratio\n  delinq_2yrs = rpois(n, 0.4),  # Number of delinquencies in past 2 years\n  inq_last_6mths = rpois(n, 0.7),  # Number of inquiries in last 6 months\n  open_acc = pmax(1, round(rnorm(n, 10, 4))),  # Number of open accounts\n  pub_rec = rbinom(n, 2, 0.06),  # Number of public records\n  revol_util = pmin(100, pmax(0, rnorm(n, 40, 20))),  # Revolving utilization\n  total_acc = pmax(open_acc, open_acc + round(rnorm(n, 8, 6)))  # Total accounts\n)\n\n# Add realistic correlations between variables\ndata <- data %>%\n  mutate(\n    # Interest rate depends on credit score and loan term\n    interest_rate = 25 - (credit_score - 300) * (15/550) + \n      ifelse(loan_term == 36, -1, ifelse(loan_term == 60, 0, 1.5)) +\n      rnorm(n, 0, 1.5),\n    \n    # Loan purpose with realistic probabilities\n    loan_purpose = sample(\n      c(\"debt_consolidation\", \"credit_card\", \"home_improvement\", \"major_purchase\", \"medical\", \"other\"), \n      n, replace = TRUE, \n      prob = c(0.45, 0.25, 0.10, 0.08, 0.07, 0.05)\n    ),\n    \n    # Add some derived features that have predictive power\n    payment_amount = (loan_amount * (interest_rate/100/12) * (1 + interest_rate/100/12)^loan_term) / \n      ((1 + interest_rate/100/12)^loan_term - 1),\n    payment_to_income_ratio = (payment_amount * 12) / income\n  )\n\n# Create a more realistic default probability model with non-linear effects\nlogit_default <- with(data, {\n  -4.5 +  # Base intercept for ~10% default rate\n    -0.03 * (age - 18) +  # Age effect (stronger for younger borrowers)\n    -0.2 * log(income/10000) +  # Log-transformed income effect\n    -0.08 * employment_length +  # Employment length effect\n    ifelse(home_ownership == \"OWN\", -0.7, ifelse(home_ownership == \"MORTGAGE\", -0.3, 0)) +  # Home ownership\n    0.3 * log(loan_amount/1000) +  # Log-transformed loan amount\n    ifelse(loan_term == 36, 0, ifelse(loan_term == 60, 0.4, 0.8)) +  # Loan term\n    0.15 * interest_rate +  # Interest rate effect\n    ifelse(loan_purpose == \"debt_consolidation\", 0.5, \n           ifelse(loan_purpose == \"credit_card\", 0.4, \n                  ifelse(loan_purpose == \"medical\", 0.6, 0))) +  # Loan purpose\n    -0.01 * (credit_score - 300) +  # Credit score (stronger effect at lower scores)\n    0.06 * dti_ratio +  # DTI ratio effect\n    0.4 * delinq_2yrs +  # Delinquencies effect (stronger effect for first delinquency)\n    0.3 * inq_last_6mths +  # Inquiries effect\n    -0.1 * log(open_acc + 1) +  # Open accounts (log-transformed)\n    0.8 * pub_rec +  # Public records (strong effect)\n    0.02 * revol_util +  # Revolving utilization\n    1.2 * payment_to_income_ratio +  # Payment to income ratio (strong effect)\n    rnorm(n, 0, 0.8)  # Add some noise for realistic variation\n})\n\n# Generate default flag with realistic default rate\nprob_default <- plogis(logit_default)\ndata$default <- factor(rbinom(n, 1, prob_default), levels = c(0, 1), labels = c(\"no\", \"yes\"))\n\n# Check class distribution\ntable(data$default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  no  yes \n9425  575 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprop.table(table(data$default))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    no    yes \n0.9425 0.0575 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize the default rate\nggplot(data, aes(x = default, fill = default)) +\n  geom_bar(aes(y = ..prop.., group = 1)) +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"Class Distribution in Credit Dataset\",\n       y = \"Percentage\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize the relationship between key variables and default rate\nggplot(data, aes(x = credit_score, y = as.numeric(default) - 1)) +\n  geom_smooth(method = \"loess\") +\n  labs(title = \"Default Rate by Credit Score\", \n       x = \"Credit Score\", y = \"Default Probability\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Examine correlation between numeric predictors\ncredit_cors <- data %>%\n  select(age, income, employment_length, loan_amount, interest_rate, \n         credit_score, dti_ratio, delinq_2yrs, revol_util, payment_to_income_ratio) %>%\n  cor()\n\ncorrplot(credit_cors, method = \"circle\", type = \"upper\", \n         tl.col = \"black\", tl.srt = 45, tl.cex = 0.7)\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n## Stratified Partitioning\n\nCredit default datasets typically exhibit class imbalance, with default events representing the minority class. We implement stratified sampling to preserve the class distribution across training, validation, and test partitions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create initial train/test split (80/20)\nset.seed(456)\ninitial_split <- initial_split(data, prop = 0.8, strata = default)\ntrain_data <- training(initial_split)\ntest_data <- testing(initial_split)\n\n# Create validation set from training data (75% train, 25% validation)\nset.seed(789)\nvalidation_split <- initial_split(train_data, prop = 0.75, strata = default)\n\n# Check class imbalance in training data\ntrain_class_counts <- table(training(validation_split)$default)\ntrain_class_props <- prop.table(train_class_counts)\n\ncat(\"Training data class distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining data class distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(train_class_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  no  yes \n5661  339 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nPercentage:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nPercentage:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(train_class_props * 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   no   yes \n94.35  5.65 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualize class imbalance\nROSE::roc.curve(training(validation_split)$default == \"yes\", \n                training(validation_split)$credit_score,\n                plotit = TRUE,                main = \"ROC Curve for Credit Score Alone\")\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nArea under the curve (AUC): 0.753\n```\n\n\n:::\n:::\n\n\n\n## Feature Engineering and Preprocessing\n\nThe following section develops a preprocessing recipe incorporating domain-specific feature engineering techniques relevant to credit risk modeling, including class imbalance handling strategies.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Examine the distributions of key variables\npar(mfrow = c(2, 2))\nhist(training(validation_split)$credit_score, \n     main = \"Credit Score Distribution\", xlab = \"Credit Score\")\n\nhist(training(validation_split)$dti_ratio, \n     main = \"DTI Ratio Distribution\", xlab = \"DTI Ratio\")\n\nhist(training(validation_split)$payment_to_income_ratio, \n     main = \"Payment to Income Ratio\", \n     xlab = \"Payment to Income Ratio\")\n\nhist(log(training(validation_split)$income), \n     main = \"Log Income Distribution\", xlab = \"Log Income\")\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a recipe\ncredit_recipe <- recipe(default ~ ., data = training(validation_split)) %>%\n  # Remove ID column\n  step_rm(customer_id) %>%\n  \n  # Convert categorical variables to factors\n  step_string2factor(home_ownership, loan_purpose) %>%\n  \n  # Create additional domain-specific features\n  step_mutate(\n    # We already have payment_to_income_ratio from data generation\n    # Add more credit risk indicators\n    credit_utilization = revol_util / 100,\n    acc_to_age_ratio = total_acc / age,\n    delinq_per_acc = ifelse(total_acc > 0, delinq_2yrs / total_acc, 0),\n    inq_rate = inq_last_6mths / (open_acc + 0.1),  # Inquiry rate relative to open accounts\n    term_factor = loan_term / 12,  # Term in years\n    log_income = log(income),  # Log transform income\n    log_loan = log(loan_amount),  # Log transform loan amount\n    payment_ratio = payment_amount / (income / 12),  # Monthly payment to monthly income\n    util_to_income = (revol_util / 100) * (dti_ratio / 100)  # Interaction term\n  ) %>%\n  \n  # Handle categorical variables\n  step_dummy(all_nominal_predictors()) %>%\n  \n  # Impute missing values (if any)\n  step_impute_median(all_numeric_predictors()) %>%\n  \n  # Transform highly skewed variables\n  step_YeoJohnson(income, loan_amount, payment_amount) %>%\n  \n  # Remove highly correlated predictors\n  step_corr(all_numeric_predictors(), threshold = 0.85) %>%\n  \n  # Normalize numeric predictors\n  step_normalize(all_numeric_predictors()) %>%\n  \n  # Remove zero-variance predictors\n  step_zv(all_predictors())\n\n# Prep the recipe to examine the steps\nprepped_recipe <- prep(credit_recipe)\nprepped_recipe\n\n# Check the transformed data\nrecipe_data <- bake(prepped_recipe, new_data = NULL)\nglimpse(recipe_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 6,000\nColumns: 27\n$ age                             <dbl> -0.58938716, 1.60129128, 0.05970275, 0…\n$ employment_length               <dbl> 1.01545119, 0.17764322, 2.35594395, -0…\n$ loan_amount                     <dbl> -0.30772032, -1.64018559, 0.01897785, …\n$ credit_score                    <dbl> -1.66355858, -1.60583467, 0.02197934, …\n$ dti_ratio                       <dbl> -1.10745919, -0.21368748, -1.26746777,…\n$ delinq_2yrs                     <dbl> -0.6423758, -0.6423758, -0.6423758, -0…\n$ inq_last_6mths                  <dbl> -0.8324634, 1.5511111, -0.8324634, -0.…\n$ open_acc                        <dbl> -0.516984456, -1.282635289, -1.2826352…\n$ pub_rec                         <dbl> -0.3429372, -0.3429372, 2.7652549, -0.…\n$ total_acc                       <dbl> 0.39969129, 0.54625046, -0.47966374, 0…\n$ interest_rate                   <dbl> 1.47394527, 1.51546694, -0.11980960, 0…\n$ default                         <fct> no, no, no, no, no, no, no, no, yes, n…\n$ credit_utilization              <dbl> -1.841097091, 2.786415973, -1.09378697…\n$ acc_to_age_ratio                <dbl> 0.50174733, -0.54849606, -0.52980631, …\n$ delinq_per_acc                  <dbl> -0.44991964, -0.44991964, -0.44991964,…\n$ inq_rate                        <dbl> -0.520358012, 1.759991048, -0.52035801…\n$ term_factor                     <dbl> 0.3219163, -0.6274559, 0.3219163, -0.6…\n$ log_income                      <dbl> 2.44464243, 0.95097048, -0.59583257, 0…\n$ payment_ratio                   <dbl> -0.70055763, -0.66316187, -0.18762635,…\n$ util_to_income                  <dbl> -1.4271447, 1.7533431, -1.1717989, -1.…\n$ home_ownership_OWN              <dbl> -0.4238857, -0.4238857, -0.4238857, -0…\n$ home_ownership_RENT             <dbl> -0.8977787, -0.8977787, 1.1136746, 1.1…\n$ loan_purpose_debt_consolidation <dbl> 1.1204596, -0.8923421, -0.8923421, -0.…\n$ loan_purpose_home_improvement   <dbl> -0.3277222, -0.3277222, 3.0508567, -0.…\n$ loan_purpose_major_purchase     <dbl> -0.2968579, -0.2968579, -0.2968579, -0…\n$ loan_purpose_medical            <dbl> -0.299178, -0.299178, -0.299178, -0.29…\n$ loan_purpose_other              <dbl> -0.2208157, -0.2208157, -0.2208157, -0…\n```\n\n\n:::\n\n```{.r .cell-code}\n# Verify\ntable(recipe_data$default)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  no  yes \n5661  339 \n```\n\n\n:::\n:::\n\n\n\n## Model Architecture and Hyperparameter Optimization\n\nThis section implements both traditional (logistic regression) and modern (XGBoost) algorithms. Logistic regression provides interpretability required for regulatory compliance, while XGBoost offers superior predictive performance. Both models undergo systematic hyperparameter tuning using cross-validation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the logistic regression model\nlog_reg_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\n# Create a logistic regression workflow\nlog_reg_workflow <- workflow() %>%\n  add_recipe(credit_recipe) %>%\n  add_model(log_reg_spec)\n\n# Define the tuning grid for logistic regression\nlog_reg_grid <- grid_regular(\n  penalty(range = c(-5, 0), trans = log10_trans()),\n  mixture(range = c(0, 1)),\n  levels = c(10, 5)\n)\n\n# Define the XGBoost model with tunable parameters\nxgb_spec <- boost_tree(\n  trees = tune(),\n  tree_depth = tune(),\n  min_n = tune(),\n  loss_reduction = tune(),\n  mtry = tune(),\n  learn_rate = tune()\n) %>%\n  set_engine(\"xgboost\", objective = \"binary:logistic\") %>%\n  set_mode(\"classification\")\n\n# Create an XGBoost workflow\nxgb_workflow <- workflow() %>%\n  add_recipe(credit_recipe) %>%\n  add_model(xgb_spec)\n\n# Define the tuning grid for XGBoost\nxgb_grid <- grid_latin_hypercube(\n  trees(range = c(50, 100)),\n  tree_depth(range = c(3, 6)),\n  min_n(range = c(2, 8)),\n  loss_reduction(range = c(0.001, 1.0)),\n  mtry(range = c(5, 20)),\n  learn_rate(range = c(-4, -1), trans = log10_trans()),\n  size = 10\n)\n\n# Create cross-validation folds with stratification\nset.seed(234)\ncv_folds <- vfold_cv(training(validation_split), v = 3, strata = default)\n\n# Define the metrics to evaluate\nclassification_metrics <- metric_set(\n  roc_auc,  # Area under the ROC curve\n  pr_auc,    # Area under the precision-recall curve\n)\n\n# Tune the logistic regression model\nset.seed(345)\nlog_reg_tuned <- tune_grid(\n  log_reg_workflow,\n  resamples = cv_folds,\n  grid = log_reg_grid,\n  metrics = classification_metrics,\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n# Tune the XGBoost model\nset.seed(456)\nxgb_tuned <- tune_grid(\n  xgb_workflow,\n  resamples = cv_folds,\n  grid = xgb_grid,\n  metrics = classification_metrics,\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n# Collect and visualize logistic regression tuning results\nlog_reg_results <- log_reg_tuned %>% collect_metrics()\nlog_reg_results %>% filter(.metric == \"roc_auc\") %>% arrange(desc(mean)) %>% head()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n   penalty mixture .metric .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.00167     1    roc_auc binary     0.853     3 0.00841 Preprocessor1_Model45\n2 0.00167     0.75 roc_auc binary     0.853     3 0.00841 Preprocessor1_Model35\n3 0.00599     0.25 roc_auc binary     0.853     3 0.00869 Preprocessor1_Model16\n4 0.00167     0.5  roc_auc binary     0.853     3 0.00836 Preprocessor1_Model25\n5 0.000464    1    roc_auc binary     0.852     3 0.00817 Preprocessor1_Model44\n6 0.00167     0.25 roc_auc binary     0.852     3 0.00837 Preprocessor1_Model15\n```\n\n\n:::\n:::\n\n\n\n## Model Finalization and Performance Evaluation\n\nThis section focuses on finalizing both models using their optimal hyperparameters and evaluating model performance on the validation dataset.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select best hyperparameters based on ROC AUC\nbest_log_reg_params <- select_best(log_reg_tuned, metric = \"roc_auc\")\nbest_xgb_params <- select_best(xgb_tuned, metric = \"roc_auc\")\n\n# Finalize workflows with best parameters\nfinal_log_reg_workflow <- log_reg_workflow %>%\n  finalize_workflow(best_log_reg_params)\n\nfinal_xgb_workflow <- xgb_workflow %>%\n  finalize_workflow(best_xgb_params)\n\n# Fit the final models on the full training data\nfinal_log_reg_model <- final_log_reg_workflow %>%\n  fit(data = training(validation_split))\n\nfinal_xgb_model <- final_xgb_workflow %>%\n  fit(data = training(validation_split))\n\n# Make predictions on the validation set with both models\nlog_reg_val_results <- final_log_reg_model %>%\n  predict(testing(validation_split)) %>%\n  bind_cols(predict(final_log_reg_model, testing(validation_split), type = \"prob\")) %>%\n  bind_cols(testing(validation_split) %>% select(default, customer_id))\n\nxgb_val_results <- final_xgb_model %>%\n  predict(testing(validation_split)) %>%\n  bind_cols(predict(final_xgb_model, testing(validation_split), type = \"prob\")) %>%\n  bind_cols(testing(validation_split) %>% select(default, customer_id))\n\n# Evaluate model performance on validation set\nlog_reg_val_metrics <- log_reg_val_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\nxgb_val_metrics <- xgb_val_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\ncat(\"Logistic Regression Validation Metrics:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLogistic Regression Validation Metrics:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(log_reg_val_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.950\n2 kap         binary         0.145\n3 mn_log_loss binary         3.64 \n4 roc_auc     binary         0.157\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nXGBoost Validation Metrics:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nXGBoost Validation Metrics:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(xgb_val_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary         0.948\n2 kap         binary         0.111\n3 mn_log_loss binary         3.24 \n4 roc_auc     binary         0.172\n```\n\n\n:::\n:::\n\n\n\n## Interpretability and Feature Importance\n\nUnderstanding feature contributions to prediction outcomes represents a critical requirement for credit scoring models, particularly for regulatory compliance and business decision-making.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract feature importance from XGBoost model\nxgb_importance <- final_xgb_model %>%\n  extract_fit_parsnip() %>%\n  vip(num_features = 15) +\n  labs(title = \"XGBoost Feature Importance\")\n\nxgb_importance\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/feature-importance-1.png){width=960}\n:::\n\n```{.r .cell-code}\n# Extract coefficients from logistic regression model\nlog_reg_importance <- final_log_reg_model %>%\n  extract_fit_parsnip() %>%\n  vip(num_features = 15) +\n  labs(title = \"Logistic Regression Coefficient Importance\")\n\nlog_reg_importance\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/feature-importance-2.png){width=960}\n:::\n\n```{.r .cell-code}\n# Create calibration plots for both models\nlog_reg_cal <- log_reg_val_results %>%\n  cal_plot_breaks(truth = default, estimate = .pred_yes, event_level = \"second\", num_breaks = 5) +\n  labs(title = \"Logistic Regression Probability Calibration\")\n\nxgb_cal <- xgb_val_results %>%\n  cal_plot_breaks(truth = default, estimate = .pred_yes, event_level = \"second\", num_breaks = 5) +\n  labs(title = \"XGBoost Probability Calibration\")\n\nlog_reg_cal\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/feature-importance-3.png){width=960}\n:::\n\n```{.r .cell-code}\nxgb_cal\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/feature-importance-4.png){width=960}\n:::\n:::\n\n\n\n##  Test Set Evaluation\n\nThe final evaluation employs the optimal model (XGBoost) on the held-out test dataset to provide an unbiased assessment of generalization performance and operational effectiveness.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make predictions on the test set with the XGBoost model\ntest_results <- final_xgb_model %>%\n  predict(test_data) %>%\n  bind_cols(predict(final_xgb_model, test_data, type = \"prob\")) %>%\n  bind_cols(test_data %>% select(default, customer_id, credit_score))\n\n# Calculate performance metrics\ntest_metrics <- test_results %>%\n  metrics(truth = default, estimate = .pred_class, .pred_yes)\n\ncat(\"Final Test Set Performance Metrics:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFinal Test Set Performance Metrics:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(test_metrics)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n  .metric     .estimator .estimate\n  <chr>       <chr>          <dbl>\n1 accuracy    binary        0.932 \n2 kap         binary        0.0316\n3 mn_log_loss binary        3.21  \n4 roc_auc     binary        0.172 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate AUC on test set\ntest_auc <- test_results %>%\n  roc_auc(truth = default, .pred_yes)\ncat(\"\\nTest Set ROC AUC: \", test_auc$.estimate, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nTest Set ROC AUC:  0.1723324 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a gains table (commonly used in credit scoring)\ngains_table <- test_results %>%\n  mutate(risk_decile = ntile(.pred_yes, 10)) %>%\n  group_by(risk_decile) %>%\n  summarise(\n    total_accounts = n(),\n    defaults = sum(default == \"yes\"),\n    non_defaults = sum(default == \"no\"),\n    default_rate = mean(default == \"yes\"),\n    avg_score = mean(credit_score)) %>% \n  arrange(desc(default_rate)) %>% \n  mutate(\n    cumulative_defaults = cumsum(defaults),\n    pct_defaults_captured = cumulative_defaults / sum(defaults),\n    cumulative_accounts = cumsum(total_accounts),\n    pct_accounts = cumulative_accounts / sum(total_accounts),\n    lift = default_rate / (sum(defaults) / sum(total_accounts))\n  )\n\n# Display the gains table\ngains_table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 11\n   risk_decile total_accounts defaults non_defaults default_rate avg_score\n         <int>          <int>    <int>        <int>        <dbl>     <dbl>\n 1          10            200       58          142        0.29       577.\n 2           9            200       26          174        0.13       628.\n 3           8            200       19          181        0.095      640.\n 4           7            200        8          192        0.04       665.\n 5           6            200        7          193        0.035      682.\n 6           4            200        6          194        0.03       727.\n 7           2            200        2          198        0.01       776.\n 8           5            200        2          198        0.01       716.\n 9           1            200        1          199        0.005      790.\n10           3            200        1          199        0.005      757.\n# ℹ 5 more variables: cumulative_defaults <int>, pct_defaults_captured <dbl>,\n#   cumulative_accounts <int>, pct_accounts <dbl>, lift <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a lift chart\nggplot(gains_table, aes(x = pct_accounts, y = lift)) +\n  geom_line() +\n  geom_point() +\n  geom_hline(yintercept = 1, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"Lift Chart\",\n       x = \"Percentage of Accounts\",\n       y = \"Lift\") +  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](modeling-with-tidymodels_files/figure-html/final-evaluation-1.png){width=672}\n:::\n:::\n\n\n\n## Key Takeaways\n  \n- **The tidymodels ecosystem provides a unified approach** to machine learning workflows, ensuring consistency and reproducibility across model development phases\n- **Domain knowledge integration is critical** for effective feature engineering \n- **Comparative modeling approaches enhance decision-making** by balancing interpretability requirements with predictive performance needs\n- **Systematic hyperparameter optimization improves model performance** while preventing overfitting through cross-validation techniques\n- **Comprehensive evaluation frameworks ensure robust assessment** of model generalization and operational effectiveness\n- **Model interpretability analysis supports regulatory compliance** and business decision-making in financial applications",
    "supporting": [
      "modeling-with-tidymodels_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
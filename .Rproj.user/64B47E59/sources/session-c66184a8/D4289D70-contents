# Think of a financial transaction like a sentence that needs translation
# Just like "The cat sat" becomes "Le chat s'est assis"

# 1. Tokenization - Break transaction into pieces
transaction <- c("amount", "sender", "receiver", "timestamp", "type")

# 2. Embedding - Convert each piece to numbers (like giving each word coordinates)
embedding_dim <- 512
transaction_embeddings <- matrix(rnorm(length(transaction) * embedding_dim), 
                                 nrow = length(transaction))

# 3. Position encoding - Add "order matters" info
# Like knowing "John pays Mary" is different from "Mary pays John"
positions <- 1:length(transaction)
pos_encoding <- sin(positions / 10000)

# 4. The transformer magic - attention mechanism
# "Which parts of this transaction should I focus on together?"
attention_weights <- function(query, key, value) {
  scores <- query %*% t(key)
  weights <- softmax(scores)
  output <- weights %*% value
  return(output)
}

# Example: Processing "$100 from Alice to Bob at 2PM for coffee"
# The model learns: amount + receiver = important for fraud detection
# sender + timestamp = important for pattern recognition
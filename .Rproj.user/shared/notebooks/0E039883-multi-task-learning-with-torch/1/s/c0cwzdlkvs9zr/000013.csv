"0","#| label: enhanced-training-loop"
"0",""
"0","# Hyperparameters"
"0","epochs <- 100  # Increased epochs since we have early stopping"
"0",""
"0","# Enhanced training history tracking"
"0","training_history <- data.frame("
"0","  epoch = integer(),"
"0","  train_reg_loss = numeric(),"
"0","  train_cls_loss = numeric(),"
"0","  train_total_loss = numeric(),"
"0","  val_reg_loss = numeric(),"
"0","  val_cls_loss = numeric(),"
"0","  val_total_loss = numeric(),"
"0","  val_accuracy = numeric()"
"0",")"
"0",""
"0","for (epoch in 1:epochs) {"
"0","  # Training phase"
"0","  model$train()"
"0","  optimizer$zero_grad()"
"0","  "
"0","  # Forward pass on training data"
"0","  outputs <- model(x_train)"
"0","  "
"0","  # Calculate training loss for each task"
"0","  train_reg_loss <- regression_loss_fn("
"0","    outputs$regression$squeeze(), "
"0","    y_reg_train"
"0","  )"
"0","  "
"0","  train_cls_loss <- classification_loss_fn("
"0","    outputs$classification$squeeze(), "
"0","    y_cls_train"
"0","  )"
"0","  "
"0","  # Weighted combined training loss"
"0","  train_total_loss <- task_weights[""regression""] * train_reg_loss + "
"0","    task_weights[""classification""] * train_cls_loss"
"0","  "
"0","  # Backward pass and optimize"
"0","  train_total_loss$backward()"
"0","  "
"0","  # Gradient clipping to prevent exploding gradients"
"0","  nn_utils_clip_grad_norm_(model$parameters, max_norm = 1.0)"
"0","  "
"0","  optimizer$step()"
"0","  "
"0","  # Validation phase"
"0","  model$eval()"
"0","  "
"0","  with_no_grad({"
"0","    val_outputs <- model(x_val)"
"0","    "
"0","    # Calculate validation losses"
"0","    val_reg_loss <- regression_loss_fn("
"0","      val_outputs$regression$squeeze(), "
"0","      y_reg_val"
"0","    )"
"0","    "
"0","    val_cls_loss <- classification_loss_fn("
"0","      val_outputs$classification$squeeze(), "
"0","      y_cls_val"
"0","    )"
"0","    "
"0","    val_total_loss <- task_weights[""regression""] * val_reg_loss + task_weights[""classification""] * val_cls_loss"
"0","    "
"0","    # Calculate validation accuracy"
"0","    val_cls_probs <- nnf_sigmoid(val_outputs$classification$squeeze())"
"0","    val_cls_preds <- (val_cls_probs > 0.5)$to(torch_int())"
"0","    val_accuracy <- (val_cls_preds == y_cls_val$to(torch_int()))$sum()$item() / length(val_indices)"
"0","  })"
"0","  "
"0","  # Record history"
"0","  training_history <- rbind("
"0","    training_history,"
"0","    data.frame("
"0","      epoch = epoch,"
"0","      train_reg_loss = as.numeric(train_reg_loss$item()),"
"0","      train_cls_loss = as.numeric(train_cls_loss$item()),"
"0","      train_total_loss = as.numeric(train_total_loss$item()),"
"0","      val_reg_loss = as.numeric(val_reg_loss$item()),"
"0","      val_cls_loss = as.numeric(val_cls_loss$item()),"
"0","      val_total_loss = as.numeric(val_total_loss$item()),"
"0","      val_accuracy = val_accuracy"
"0","    )"
"0","  )"
"0","  "
"0","  # Print progress every 25 epochs"
"0","  if (epoch %% 25 == 0 || epoch == 1) {"
"0","    cat(sprintf(""Epoch %d - Train Loss: %.4f, Val Loss: %.4f, Val Acc: %.3f\n"", "
"0","                epoch, "
"0","                train_total_loss$item(), "
"0","                val_total_loss$item(), "
"0","                val_accuracy))"
"0","  }"
"0",""
"0","}"
"1","Epoch 1 - Train Loss: 0.0218, Val Loss: 0.0522, Val Acc: 0.964
"
"1","Epoch 25 - Train Loss: 0.0209, Val Loss: 0.0507, Val Acc: 0.964
"
"1","Epoch 50 - Train Loss: 0.0207, Val Loss: 0.0524, Val Acc: 0.964
"
"1","Epoch 75 - Train Loss: 0.0204, Val Loss: 0.0524, Val Acc: 0.964
"
"1","Epoch 100 - Train Loss: 0.0202, Val Loss: 0.0519, Val Acc: 0.964
"

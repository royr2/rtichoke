"0","#| label: setup-training"
"0",""
"0","# Loss functions"
"0","regression_loss_fn <- nnf_mse_loss  # Mean squared error for regression"
"0","classification_loss_fn <- nnf_binary_cross_entropy_with_logits  # Binary cross-entropy for classification"
"0",""
"0","# Optimizer with weight decay for L2 regularization"
"0","optimizer <- optim_adam(model$parameters, lr = 0.01, weight_decay = 1e-4)"
"0",""
"0","# Task weights - these control the relative importance of each task"
"0","task_weights <- c(regression = 0.5, classification = 0.5)"
"0",""
"0","# Early stopping parameters"
"0","patience <- 15"
"0","best_val_loss <- Inf"
"0","patience_counter <- 0"
"0","best_model_state <- NULL"
"0",""
"0","# Validation split from training data"
"0","val_size <- round(0.2 * length(train_idx))"
"0","val_indices <- sample(train_idx, val_size)"
"0","train_indices <- setdiff(train_idx, val_indices)"
"0",""
"0","# Create validation sets"
"0","x_val <- x[val_indices, ]"
"0","y_reg_val <- y_regression[val_indices]"
"0","y_cls_val <- y_classification[val_indices]"
"0",""
"0","# Update training sets"
"0","x_train <- x[train_indices, ]"
"0","y_reg_train <- y_regression[train_indices]"
"0","y_cls_train <- y_classification[train_indices]"
"0",""
"0","cat(""Updated split - Training:"", length(train_indices), "
"0","    ""Validation:"", length(val_indices), "
"0","    ""Testing:"", length(test_idx), ""\n"")"
"1","Updated split - Training:"
"1"," "
"1","560"
"1"," "
"1","Validation:"
"1"," "
"1","140"
"1"," "
"1","Testing:"
"1"," "
"1","300"
"1"," "
"1","
"

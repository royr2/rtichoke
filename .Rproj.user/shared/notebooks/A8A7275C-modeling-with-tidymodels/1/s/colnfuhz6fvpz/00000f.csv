"0","# Define the logistic regression model"
"0","log_reg_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%"
"0","  set_engine(""glmnet"") %>%"
"0","  set_mode(""classification"")"
"0",""
"0","# Create a logistic regression workflow"
"0","log_reg_workflow <- workflow() %>%"
"0","  add_recipe(credit_recipe) %>%"
"0","  add_model(log_reg_spec)"
"0",""
"0","# Define the tuning grid for logistic regression"
"0","log_reg_grid <- grid_regular("
"0","  penalty(range = c(-5, 0), trans = log10_trans()),"
"0","  mixture(range = c(0, 1)),"
"0","  levels = c(10, 5)"
"0",")"
"0",""
"0","# Define the XGBoost model with tunable parameters"
"0","xgb_spec <- boost_tree("
"0","  trees = tune(),"
"0","  tree_depth = tune(),"
"0","  min_n = tune(),"
"0","  loss_reduction = tune(),"
"0","  mtry = tune(),"
"0","  learn_rate = tune()"
"0",") %>%"
"0","  set_engine(""xgboost"", objective = ""binary:logistic"", scale_pos_weight = 5) %>%"
"0","  set_mode(""classification"")"
"0",""
"0","# Create an XGBoost workflow"
"0","xgb_workflow <- workflow() %>%"
"0","  add_recipe(credit_recipe) %>%"
"0","  add_model(xgb_spec)"
"0",""
"0","# Define the tuning grid for XGBoost"
"0","xgb_grid <- grid_latin_hypercube("
"0","  trees(range = c(100, 500)),"
"0","  tree_depth(range = c(3, 10)),"
"0","  min_n(range = c(2, 20)),"
"0","  loss_reduction(range = c(0.001, 1.0)),"
"0","  mtry(range = c(5, 20)),"
"0","  learn_rate(range = c(-4, -1), trans = log10_trans()),"
"0","  size = 15"
"0",")"
"0",""
"0","# Create cross-validation folds with stratification"
"0","set.seed(234)"
"0","cv_folds <- vfold_cv(training(validation_split), v = 3, strata = default)"
"0",""
"0","# Define the metrics to evaluate"
"0","classification_metrics <- metric_set("
"0","  roc_auc,  # Area under the ROC curve"
"0","  pr_auc,    # Area under the precision-recall curve"
"0",")"
"0",""
"0","# Tune the logistic regression model"
"0","set.seed(345)"
"0","log_reg_tuned <- tune_grid("
"0","  log_reg_workflow,"
"0","  resamples = cv_folds,"
"0","  grid = log_reg_grid,"
"0","  metrics = classification_metrics,"
"0","  control = control_grid(save_pred = TRUE, verbose = TRUE)"
"0",")"
"0",""
"0","# Tune the XGBoost model"
"0","set.seed(456)"
"0","xgb_tuned <- tune_grid("
"0","  xgb_workflow,"
"0","  resamples = cv_folds,"
"0","  grid = xgb_grid,"
"0","  metrics = classification_metrics,"
"0","  control = control_grid(save_pred = TRUE, verbose = TRUE)"
"0",")"
"0",""
"0","# Collect and visualize logistic regression tuning results"
"0","log_reg_results <- log_reg_tuned %>% collect_metrics()"
"0","log_reg_results %>% filter(.metric == ""roc_auc"") %>% arrange(desc(mean)) %>% head()"

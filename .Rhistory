combined <- rbind(pop_perf, seg_perf)
# Create a line plot comparing bad rates at different approval thresholds
library(ggplot2)
ggplot(combined, aes(x = cum_pct, y = cum_bad_rate, color = model, group = model)) +
geom_line(size = 1) +                                  # Connect points with lines
geom_point(size = 3) +                                 # Add points at each threshold
scale_x_continuous(labels = percent_format(),         # Format x-axis as percentages
breaks = seq(0, 1, 0.1)) +         # Show 10% increments
scale_y_continuous(labels = percent_format()) +       # Format y-axis as percentages
labs(x = "Approval Rate",
y = "Bad Rate",
title = "Bad Rate by Approval Rate",
subtitle = "Comparison of Population vs. Segment Model") +
theme_minimal() +                                     # Clean visual theme
theme(legend.title = element_blank(),                 # Remove legend title
legend.position = "bottom")                      # Position legend at bottom
combined
combined
ggplot(combined, aes(x = cum_pct, y = cum_bad_rate, color = model, group = model)) +
geom_line(size = 1) +                                  # Connect points with lines
geom_point(size = 3)
pop_perf
smple %>%
filter(segment == "KG")
#| label: model-comparison
# Evaluate population model performance on the KG segment
pop_perf <- smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count) %>% # Bad rate at each approval threshold
filter(cum_pct %in% seq(0.1, 1, 0.1))          # Sample at 10% intervals
# Evaluate segment model performance on the KG segment
seg_perf <- smple %>%
filter(segment == "KG") %>%                     # Same segment
mutate(pred = predict(mdl_seg, newdata = .),   # But using segment model
score = scaling_func(pred),
total = n()) %>%
arrange(desc(score)) %>%
mutate(cum_count = row_number(),
cum_pct = cum_count / total,
cum_bad = cumsum(bad_flag),
cum_bad_rate = cum_bad / cum_count) %>%
filter(cum_pct %in% seq(0.1, 1, 0.1))
#| label: visualization
# Combine results from both models for plotting
pop_perf$model <- "Population Model"
seg_perf$model <- "Segment Model"
combined <- rbind(pop_perf, seg_perf)
# Create a line plot comparing bad rates at different approval thresholds
library(ggplot2)
ggplot(combined, aes(x = cum_pct, y = cum_bad_rate, color = model, group = model)) +
geom_line(size = 1) +                                  # Connect points with lines
geom_point(size = 3) +                                 # Add points at each threshold
scale_x_continuous(labels = percent_format(),         # Format x-axis as percentages
breaks = seq(0, 1, 0.1)) +         # Show 10% increments
scale_y_continuous(labels = percent_format()) +       # Format y-axis as percentages
labs(x = "Approval Rate",
y = "Bad Rate",
title = "Bad Rate by Approval Rate",
subtitle = "Comparison of Population vs. Segment Model") +
theme_minimal() +                                     # Clean visual theme
theme(legend.title = element_blank(),                 # Remove legend title
legend.position = "bottom")                      # Position legend at bottom
smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count)
smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count)
smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count) %>% # Bad rate at each approval threshold
filter(cum_pct %in% seq(0.1, 1, 0.1))
smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count) %>% # Bad rate at each approval threshold
filter(cum_pct %in% seq(0.1, 1, 0.1)) %>% View
smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count) %>% View
smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count)
smple %>%
filter(segment == "KG") %>%                     # Focus on KG segment only
mutate(pred = predict(mdl_pop, newdata = .),   # Get model predictions
score = scaling_func(pred),             # Convert to credit score scale
total = n()) %>%                         # Total number of KG customers
arrange(desc(score)) %>%                        # Sort by score (best first)
mutate(cum_count = row_number(),               # Cumulative count
cum_pct = cum_count / total,            # Approval rate
cum_bad = cumsum(bad_flag),             # Cumulative bad loans
cum_bad_rate = cum_bad / cum_count) %>% View
#| label: installation
#| eval: false
# install.packages("torch")
library(torch)
# torch::install_torch()
#| label: load-libraries
#| echo: false
# Load required libraries
library(torch)
library(ggplot2)
#| label: generate-data
# Set seed for reproducibility
set.seed(42)
# Generate training data: y = 3x + 2 + noise
x <- torch_randn(100, 1)
y <- 3 * x + 2 + torch_randn(100, 1) * 0.3
# Display the first few data points
head(data.frame(
x = as.numeric(x$squeeze()),
y = as.numeric(y$squeeze())
))
#| label: define-network
# Define a simple feedforward neural network
net <- nn_module(
initialize = function() {
# Define layers
self$fc1 <- nn_linear(1, 8)  # Input layer to hidden layer (1 -> 8 neurons)
self$fc2 <- nn_linear(8, 1)  # Hidden layer to output layer (8 -> 1 neuron)
},
forward = function(x) {
# Define forward pass
x %>%
self$fc1() %>%     # First linear transformation
nnf_relu() %>%     # ReLU activation function
self$fc2()         # Second linear transformation
}
)
# Instantiate the model
model <- net()
# Display model structure
print(model)
#| label: setup-training
# Set up optimizer (Adam optimizer with learning rate 0.01)
optimizer <- optim_adam(model$parameters, lr = 0.01)
# Define loss function (Mean Squared Error for regression)
loss_fn <- nnf_mse_loss
cat("Optimizer:", class(optimizer)[1], "\n")
cat("Loss function:", "Mean Squared Error\n")
cat("Learning rate:", 0.01, "\n")
#| label: training-loop
# Store loss values for plotting
loss_history <- numeric(300)
# Training loop
for(epoch in 1:300) {
# Set model to training mode
model$train()
# Reset gradients
optimizer$zero_grad()
# Forward pass
y_pred <- model(x)
# Calculate loss
loss <- loss_fn(y_pred, y)
# Backward pass
loss$backward()
# Update parameters
optimizer$step()
# Store loss for plotting
loss_history[epoch] <- loss$item()
# Print progress every 50 epochs
if(epoch %% 50 == 0) {
cat(sprintf("Epoch %d, Loss: %.6f\n", epoch, loss$item()))
}
}
#| label: training-progress
#| fig-width: 10
#| fig-height: 6
# Create a data frame for plotting
training_df <- data.frame(
epoch = 1:300,
loss = loss_history
)
# Plot training loss
ggplot(training_df, aes(x = epoch, y = loss)) +
geom_line(color = "#2c3e50", size = 1) +
labs(
title = "Training Loss Over Time",
subtitle = "Neural Network Learning Progress",
x = "Epoch",
y = "Mean Squared Error Loss"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12, color = "gray60")
)
#| label: visualize-results
#| fig-width: 10
#| fig-height: 8
# Set model to evaluation mode
model$eval()
# Generate predictions
with_no_grad({
y_pred <- model(x)
})
# Convert to R vectors for plotting
x_np <- as.numeric(x$squeeze())
y_np <- as.numeric(y$squeeze())
y_pred_np <- as.numeric(y_pred$squeeze())
# Create data frame for ggplot
plot_df <- data.frame(
x = x_np,
y_actual = y_np,
y_predicted = y_pred_np
)
# Create the plot
ggplot(plot_df, aes(x = x)) +
geom_point(aes(y = y_actual, color = "Actual"), alpha = 0.7, size = 2) +
geom_point(aes(y = y_predicted, color = "Predicted"), alpha = 0.7, size = 2) +
geom_smooth(aes(y = y_predicted), method = "loess", se = FALSE,
color = "#e74c3c", linetype = "dashed") +
labs(
title = "Neural Network Regression Results",
subtitle = "Comparing actual vs predicted values",
x = "Input (x)",
y = "Output (y)",
color = "Data Type"
) +
scale_color_manual(values = c("Actual" = "#3498db", "Predicted" = "#e74c3c")) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12, color = "gray60"),
legend.position = "top"
)
#| label: performance-analysis
# Calculate performance metrics
mse <- mean((y_pred_np - y_np)^2)
rmse <- sqrt(mse)
mae <- mean(abs(y_pred_np - y_np))
r_squared <- cor(y_pred_np, y_np)^2
# Create performance summary
performance_summary <- data.frame(
Metric = c("Mean Squared Error", "Root Mean Squared Error",
"Mean Absolute Error", "R-squared"),
Value = c(mse, rmse, mae, r_squared)
)
print(performance_summary)
# Compare with true relationship (y = 3x + 2)
# Generate predictions on a grid for comparison
x_grid <- torch_linspace(-3, 3, 100)$unsqueeze(2)
with_no_grad({
y_grid_pred <- model(x_grid)
})
x_grid_np <- as.numeric(x_grid$squeeze())
y_grid_pred_np <- as.numeric(y_grid_pred$squeeze())
y_grid_true <- 3 * x_grid_np + 2
# Plot comparison
comparison_df <- data.frame(
x = x_grid_np,
y_true = y_grid_true,
y_predicted = y_grid_pred_np
)
ggplot(comparison_df, aes(x = x)) +
geom_line(aes(y = y_true, color = "True Function"), size = 2) +
geom_line(aes(y = y_predicted, color = "Neural Network"), size = 2, linetype = "dashed") +
geom_point(data = plot_df, aes(y = y_actual), alpha = 0.3, color = "gray50") +
labs(
title = "Neural Network vs True Function",
subtitle = "How well did our model learn the underlying pattern?",
x = "Input (x)",
y = "Output (y)",
color = "Function Type"
) +
scale_color_manual(values = c("True Function" = "#2c3e50", "Neural Network" = "#e74c3c")) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12, color = "gray60"),
legend.position = "top"
)
#| label: examine-parameters
# Extract learned parameters
fc1_weight <- as.matrix(model$fc1$weight$detach())
fc1_bias <- as.numeric(model$fc1$bias$detach())
fc2_weight <- as.matrix(model$fc2$weight$detach())
fc2_bias <- as.numeric(model$fc2$bias$detach())
cat("First layer (fc1) parameters:\n")
cat("Weight matrix shape:", dim(fc1_weight), "\n")
cat("Bias vector length:", length(fc1_bias), "\n\n")
cat("Second layer (fc2) parameters:\n")
cat("Weight matrix shape:", dim(fc2_weight), "\n")
cat("Bias value:", fc2_bias, "\n\n")
# Display first layer weights and biases
cat("First layer weights (sample):\n")
print(round(fc1_weight[1:5], 4))
cat("\nFirst layer biases (sample):\n")
print(round(fc1_bias[1:5], 4))
#| label: architecture-comparison
#| fig-width: 12
#| fig-height: 8
# Define different network architectures
create_network <- function(hidden_sizes) {
nn_module(
initialize = function(hidden_sizes) {
self$layers <- nn_module_list()
# Input layer
prev_size <- 1
for(i in seq_along(hidden_sizes)) {
self$layers$append(nn_linear(prev_size, hidden_sizes[i]))
prev_size <- hidden_sizes[i]
}
# Output layer
self$layers$append(nn_linear(prev_size, 1))
},
forward = function(x) {
for(i in 1:(length(self$layers) - 1)) {
x <- nnf_relu(self$layers[[i]](x))
}
# No activation on output layer
self$layers[[length(self$layers)]](x)
}
)
}
# Train different architectures
architectures <- list(
"Simple (8)" = c(8),
"Deep (16-8)" = c(16, 8),
"Wide (32)" = c(32),
"Very Deep (16-16-8)" = c(16, 16, 8)
)
results <- list()
for(arch_name in names(architectures)) {
cat("Training", arch_name, "architecture...\n")
# Create and train model
net_class <- create_network(architectures[[arch_name]])
model_temp <- net_class(architectures[[arch_name]])
optimizer_temp <- optim_adam(model_temp$parameters, lr = 0.01)
# Quick training (fewer epochs for comparison)
for(epoch in 1:200) {
model_temp$train()
optimizer_temp$zero_grad()
y_pred_temp <- model_temp(x)
loss_temp <- loss_fn(y_pred_temp, y)
loss_temp$backward()
optimizer_temp$step()
}
# Generate predictions
model_temp$eval()
with_no_grad({
y_pred_arch <- model_temp(x_grid)
})
results[[arch_name]] <- data.frame(
x = x_grid_np,
y_pred = as.numeric(y_pred_arch$squeeze()),
architecture = arch_name
)
}
# Combine results
all_results <- do.call(rbind, results)
# Plot comparison
ggplot(all_results, aes(x = x, y = y_pred, color = architecture)) +
geom_line(size = 1.2) +
geom_line(data = comparison_df, aes(y = y_true, color = "True Function"),
size = 2, linetype = "solid") +
geom_point(data = plot_df, aes(y = y_actual),
color = "gray50", alpha = 0.3, inherit.aes = FALSE) +
labs(
title = "Comparison of Different Neural Network Architectures",
subtitle = "How network depth and width affect learning",
x = "Input (x)",
y = "Output (y)",
color = "Architecture"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12, color = "gray60"),
legend.position = "top"
)
all_results
ggplot(all_results, aes(x = x, y = y_pred, color = architecture)) +
geom_line(size = 1.2) +
geom_line(data = comparison_df, aes(y = y_true, color = "True Function"),
size = 2, linetype = "solid") +
geom_point(data = plot_df, aes(y = y_actual),
color = "gray50", alpha = 0.3, inherit.aes = FALSE)
plot_df
#| label: architecture-comparison
#| fig-width: 12
#| fig-height: 8
# Define different network architectures
create_network <- function(hidden_sizes) {
nn_module(
initialize = function(hidden_sizes) {
self$layers <- nn_module_list()
# Input layer
prev_size <- 1
for(i in seq_along(hidden_sizes)) {
self$layers$append(nn_linear(prev_size, hidden_sizes[i]))
prev_size <- hidden_sizes[i]
}
# Output layer
self$layers$append(nn_linear(prev_size, 1))
},
forward = function(x) {
for(i in 1:(length(self$layers) - 1)) {
x <- nnf_relu(self$layers[[i]](x))
}
# No activation on output layer
self$layers[[length(self$layers)]](x)
}
)
}
# Train different architectures
architectures <- list(
"Simple (8)" = c(8),
"Deep (16-8)" = c(16, 8),
"Wide (32)" = c(32),
"Very Deep (16-16-8)" = c(16, 16, 8)
)
results <- list()
for(arch_name in names(architectures)) {
cat("Training", arch_name, "architecture...\n")
# Create and train model
net_class <- create_network(architectures[[arch_name]])
model_temp <- net_class(architectures[[arch_name]])
optimizer_temp <- optim_adam(model_temp$parameters, lr = 0.01)
# Quick training (fewer epochs for comparison)
for(epoch in 1:200) {
model_temp$train()
optimizer_temp$zero_grad()
y_pred_temp <- model_temp(x)
loss_temp <- loss_fn(y_pred_temp, y)
loss_temp$backward()
optimizer_temp$step()
}
# Generate predictions
model_temp$eval()
with_no_grad({
y_pred_arch <- model_temp(x_grid)
})
results[[arch_name]] <- data.frame(
x = x_grid_np,
y_pred = as.numeric(y_pred_arch$squeeze()),
architecture = arch_name
)
}
# Combine results
all_results <- do.call(rbind, results)
# Plot comparison
ggplot(all_results, aes(x = x, y = y_pred, color = architecture)) +
geom_line(size = 1.2) +
geom_line(data = comparison_df, aes(y = y_true, color = "True Function"),
size = 2, linetype = "solid") +
geom_point(data = plot_df, aes(x = x, y = y_actual),
color = "gray50", alpha = 0.3, inherit.aes = FALSE) +
labs(
title = "Comparison of Different Neural Network Architectures",
subtitle = "How network depth and width affect learning",
x = "Input (x)",
y = "Output (y)",
color = "Architecture"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold"),
plot.subtitle = element_text(size = 12, color = "gray60"),
legend.position = "top"
)
.Rversion
R.version

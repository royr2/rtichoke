---
title: "Tutorial: Generating Correlated Random Numbers in R Using Matrix Methods"
date: "2024-03-19"
categories: [R, Statistics, Simulation]
image: "../images/correlated.png"
execute:
  echo: true
  warning: false
  message: false
  eval: true
---

## Introduction

The generation of random data with specified correlation patterns represents a fundamental requirement in statistical simulation and algorithm testing. This tutorial provides a comprehensive methodology for creating correlated random numbers in R using matrix-based approaches, with particular emphasis on the Cholesky decomposition method. The techniques presented enable the development of realistic synthetic datasets with precisely controlled correlation structures, essential for robust statistical analysis and model validation.

## The Cholesky Decomposition Method: A Four-Step Implementation

```{r}
#| label: setup

# 1. Define your target correlation matrix
cor_mat <- matrix(c(1, 0.3, 
                   0.3, 1), nrow = 2, byrow = TRUE)

# 2. Apply Cholesky decomposition
chol_mat <- chol(cor_mat)

# 3. Generate uncorrelated random numbers
old_random <- matrix(rnorm(2000), ncol = 2)

# 4. Transform to create correlation
new_random <- old_random %*% chol_mat

# Verify the correlation
cor(new_random)
```

The resulting `new_random` matrix contains values exhibiting approximately the target correlation structure. This technique employs Cholesky decomposition to construct a transformation matrix that induces the desired correlation when applied to uncorrelated input data.

## Critical Implementation Considerations and Common Pitfalls

### Input Data Independence Requirement

The input data must demonstrate statistical independence for the Cholesky method to function correctly. Pre-existing correlations in the input data compromise the method's ability to achieve target correlation structures:

```{r}
#| label: correlation-comparison

# What happens with already correlated input?
simulate_correlation <- function(input_correlation, target = 0.3) {
  results <- replicate(1000, {
    # Create input with specified correlation
    x <- rnorm(1000)
    y <- input_correlation * x + rnorm(1000, sd = sqrt(1 - input_correlation^2))
    
    # Apply our method
    old_random <- cbind(x, y)
    chol_mat <- chol(matrix(c(1, target, target, 1), ncol = 2))
    new_random <- old_random %*% chol_mat
    
    # Return resulting correlation
    cor(new_random)[1,2]
  })
  return(results)
}

# Compare results with different input correlations
par(mfrow = c(1, 2))
hist(simulate_correlation(0.8), main = "Starting with Correlated Data",
     xlim = c(0, 1), col = "salmon")
hist(simulate_correlation(0.001), main = "Starting with Random Data",     xlim = c(0, 1), col = "lightblue")
```

When input data contains pre-existing correlation patterns, the Cholesky method cannot effectively override these relationships to establish the desired target correlation structure.

### Distribution Consistency Requirement

Optimal results require consistent probability distributions across all variables in the transformation:

```{r}
#| label: distribution-comparison

# Different distributions cause problems
set.seed(123)
x1 <- rchisq(1000, df = 3)  # Chi-squared (skewed)
y1 <- rnorm(1000)           # Normal (symmetric)
old_mixed <- cbind(x1, y1)

# Same distribution works better
x2 <- rchisq(1000, df = 3)
y2 <- rchisq(1000, df = 3)
old_same <- cbind(x2, y2)

# Apply the same transformation to both
chol_mat <- chol(matrix(c(1, 0.7, 0.7, 1), ncol = 2))
new_mixed <- old_mixed %*% chol_mat
new_same <- old_same %*% chol_mat

# Compare results
cat("Target correlation: 0.7\n")
cat("Mixed distributions result:", round(cor(new_mixed)[1,2], 3), "\n")
cat("Same distribution result:", round(cor(new_same)[1,2], 3))
```

The combination of different probability distributions (such as normal and chi-squared) can result in unexpected correlation patterns following the Cholesky transformation.

### Distribution Property Preservation Challenges

The Cholesky transformation may fundamentally alter the statistical properties of the original data:

```{r}
#| label: property-changes

# Original positive-only distribution
x <- rchisq(1000, df = 3)  # Always positive
y <- rchisq(1000, df = 3)  # Always positive
old_random <- cbind(x, y)

# Apply negative correlation
chol_mat <- chol(matrix(c(1, -0.7, -0.7, 1), ncol = 2))
new_random <- old_random %*% chol_mat

# Check what happened
cat("Original data range:", round(range(old_random), 2), "\n")
cat("Transformed data range:", round(range(new_random), 2), "\n")
cat("Negative values in result:", sum(new_random < 0), "out of", length(new_random))
```

The Cholesky transformation can fundamentally modify data characteristics, such as introducing negative values into previously positive-only distributions, thereby altering the fundamental nature of the data.

## Alternative Implementation: The mvtnorm Package Approach

For practical applications requiring efficient implementation, the `mvtnorm` package provides a streamlined solution for generating multivariate normal distributions with specified correlation structures:

```{r}
#| label: mvtnorm

# Load the package
library(mvtnorm)

# Define means and covariance matrix
means <- c(10, 20)  # Mean for each variable
sigma <- matrix(c(4, 2,   # Covariance matrix
                  2, 3), ncol = 2)

# See the implied correlation
cov2cor(sigma)

# Generate correlated normal data in one step
x <- rmvnorm(n = 1000, mean = means, sigma = sigma)

# Verify the result
round(cor(x), 3)
```

## Methodological Selection Criteria

### Cholesky Decomposition Method

**Recommended Applications:**
- Educational contexts requiring understanding of underlying mathematical principles
- Non-normal distribution requirements
- Custom correlation structure development
- Theoretical research applications

### mvtnorm Package Implementation

**Recommended Applications:**
- Production environments requiring rapid multivariate normal data generation
- Scenarios demanding precise control over means and variance parameters
- High-dimensional variable systems
- Operational analytical workflows

## Key Takeaways

This tutorial has demonstrated comprehensive methodologies for generating correlated random numbers in R. The essential insights include:

- **Cholesky decomposition provides a mathematical foundation** for transforming uncorrelated data into correlated structures through matrix operations
- **Input data independence is critical** for successful correlation induction; pre-existing correlations compromise the transformation effectiveness
- **Distribution consistency across variables ensures optimal results** and prevents unexpected correlation artifacts
- **The transformation process can alter fundamental data properties**, requiring careful consideration of distributional characteristics
- **The mvtnorm package offers production-ready solutions** for multivariate normal data generation with specified correlation structures
- **Method selection depends on specific requirements**: Cholesky for educational and custom applications, mvtnorm for operational efficiency

These techniques form the foundation for advanced statistical simulation, enabling the creation of realistic synthetic datasets essential for robust model validation and algorithm testing across diverse analytical domains.